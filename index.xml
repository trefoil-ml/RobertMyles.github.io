<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Lithium Theme</title>
    <link>/</link>
    <description>Recent content on Lithium Theme</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 01 Feb 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>How to make a GitHub pages blog with RStudio and Hugo</title>
      <link>/2017/02/01/how-to-make-a-github-pages-blog-with-rstudio-and-hugo/</link>
      <pubDate>Wed, 01 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/02/01/how-to-make-a-github-pages-blog-with-rstudio-and-hugo/</guid>
      <description>&lt;!-- BLOGDOWN-BODY-BEFORE

/BLOGDOWN-BODY-BEFORE --&gt;




&lt;!-- BLOGDOWN-HEAD




/BLOGDOWN-HEAD --&gt;
</description>
    </item>
    
    <item>
      <title>Ranking Brad Pitt’s Movies in R</title>
      <link>/brad_pitt_movies.html</link>
      <pubDate>Wed, 11 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>/brad_pitt_movies.html</guid>
      <description>&lt;!-- BLOGDOWN-BODY-BEFORE

/BLOGDOWN-BODY-BEFORE --&gt;

&lt;p&gt;So I saw &lt;a href=&#34;http://movies.prettyfamous.com/stories/24289/ranking-every-brad-pitt-movie-from-worst-to-first&#34;&gt;this&lt;/a&gt; blog post, in which &lt;a href=&#34;http://www.prettyfamous.com/&#34;&gt;Pretty Famous&lt;/a&gt; ranked every one of Brad Pitt’s movies (I have no idea how I came across it, I’m not particularly a movie buff or a fan of Señor Pitt, but anyway). Then I wondered how easy/hard it would be to do something like that in R. Pretty Famous used a few sources, but here I’m going to stick to Rotten Tomatoes, since it’s a pretty well-known movie ratings site, maybe the most well-known. Pretty famous, you could say (ugh, apologies).&lt;/p&gt;
&lt;p&gt;For those who don’t have much experience scraping information from the web, we first need to find the unique url for Brad Pitt. In other words, his “&lt;a href=&#34;https://www.rottentomatoes.com/celebrity/brad_pitt/&#34;&gt;personal page&lt;/a&gt;” on Rotten Tomatoes. Once we’ve done that, we need to identify what part of the page we want to scrape. In this case, that is the “Movies” table. You can right-click on this table and click “Inspect” or “Inspect Element” on your browser (I’m using Chrome on a macbook, but it should be pretty similar on other browsers). Once you find the &lt;em&gt;actual&lt;/em&gt; table, instead of a &lt;code&gt;&amp;lt;div&amp;gt;&lt;/code&gt; element holding it, or just a title, then copy the selector of that element. This can be done on Chrome by right clicking the line in the ‘Elements’ panel that comes up when you right-click and click ‘Inspect’. You will have an option to ‘Copy’, then choose ‘Copy selector’ (you can choose xpath if you want, but css is simpler). In any case, the elements will be highlighted on the page as you click on them.&lt;/p&gt;
&lt;p&gt;In R, we can use the &lt;a href=&#34;https://github.com/hadley/rvest&#34;&gt;rvest&lt;/a&gt; package to read the page, store the nodes of the web document that we want and then extract the table from this node set. The ‘table’ ends up as a list of two dataframes, Brad Pitt’s films and TV appearances. His movies are in the first dataframe and so we extract that one out, as a dataframe called ‘movies’. Of course, in some of these movies he had a larger role than others, and can be said to have had a bigger impact on the rating score. But, hey, this is informal analysis.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(rvest)
library(lubridate)

url &amp;lt;- &amp;quot;https://www.rottentomatoes.com/celebrity/brad_pitt/&amp;quot;
page &amp;lt;- read_html(url)
tb_x &amp;lt;- html_nodes(page, css = &amp;quot;#filmographyTbl&amp;quot;)
tb &amp;lt;- html_table(tb_x)
movies &amp;lt;- tb[[1]]
head(movies)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         RATING                               TITLE
## 1 No Score Yet                       World War Z 2
## 2          87%                  The Lost City of Z
## 3 No Score Yet                       Brad&amp;#39;s Status
## 4          61%                              Allied
## 5          98%                           Moonlight
## 6          92% Voyage of Time: The IMAX Experience
##                                                                                                                                             CREDIT
## 1 Gerry Lane\n                                                \n                                \n                                        Producer
## 2                                                                                                                               Executive Producer
## 3                                                                                                                                            Actor
## 4                                                                                                                                        Max Vatan
## 5                                                                                                                               Executive Producer
## 6                                                                                                                                         Producer
##   YEAR
## 1 2017
## 2 2017
## 3 2017
## 4 2016
## 5 2016
## 6 2016&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we’ve got Mr. Pitt’s movies in a dataframe, with their rating, title, producer credits and year. Since anything with “No Score Yet” is not of particular use to us, let’s remove it. We also could do with changing “87%” to an actual number, i.e. 0.87, and we’ll take out the movies in which he had no acting role, and try to clean up all those spaces and new lines.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;#39;%ni%&amp;#39; &amp;lt;- Negate(&amp;#39;%in%&amp;#39;)
movies &amp;lt;- movies %&amp;gt;%
  mutate(CREDIT = gsub(&amp;quot;\\r\\n&amp;quot;, &amp;quot;&amp;quot;, CREDIT)) %&amp;gt;%
  filter(RATING != &amp;quot;No Score Yet&amp;quot;,
         CREDIT %ni% c(&amp;quot;Producer&amp;quot;, &amp;quot;Executive Producer&amp;quot;),
         TITLE %ni% c(&amp;quot;Selma&amp;quot;, &amp;quot;The Time Traveler&amp;#39;s Wife&amp;quot;)) %&amp;gt;%
  mutate(RATING = gsub(&amp;quot;%&amp;quot;, &amp;quot;&amp;quot;, RATING),
         RATING = as.numeric(RATING),
         RATING = RATING/100)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So how do the ratings for his Pittness stack up? Let’s have a look-see, Rotten Tomatoes style:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(grid)
library(png)

tomato &amp;lt;- readPNG(&amp;quot;rmd_images/tomato.png&amp;quot;)
g &amp;lt;- rasterGrob(tomato, interpolate=TRUE)

ggplot(movies, aes(x = RATING)) +
  geom_histogram(bins = 20, fill = &amp;quot;#EE4000&amp;quot;, colour = &amp;quot;yellow&amp;quot;) +
  theme_classic() +
  theme(panel.background = element_rect(fill = &amp;quot;#3A9425&amp;quot;)) +
  annotation_custom(g, xmin = 0, xmax = 0.25, ymin = 4, ymax = 6)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/brad_pitt_movies.htmlfigures/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;(You can get the tomato image from &lt;a href=&#34;http://static.tvtropes.org/pmwiki/pub/images/rotten_tomatoes_8290.jpg&#34;&gt;here&lt;/a&gt;. Convert it to png and strip out (most of) the white background using &lt;a href=&#34;https://www.imagemagick.org/script/index.php&#34;&gt;ImageMagick&lt;/a&gt; – the command on a mac is &lt;code&gt;convert rotten_tomatoes.jpg -transparent white tomato.png&lt;/code&gt;.)&lt;/p&gt;
&lt;p&gt;Not so bad! Got some not-so-greats, but quite a lot of highly rated movies. I’m surprised, actually. In fact the mean and median values are:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(movies$RATING)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.6508511&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;median(movies$RATING)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.7&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I wonder if his movies have gotten better? I was always under the impression that Brad Pitt was an actor who, like Leonardo DiCaprio, actually learned to act over time, instead of already being a talented actor when he started. Fair credit to them, though, they could have just rested on their laurels after they first became famous.&lt;/p&gt;
&lt;p&gt;Let’s have a look at how the ratings have change over time and see if Brad has gotten better or worse, judging by the film that came before.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;movies &amp;lt;- movies %&amp;gt;%
  arrange(YEAR) %&amp;gt;%
  mutate(difference = c(0, diff(RATING, lag = 1)),
         date_counter = 1:nrow(.))

ggplot(movies, aes(x = date_counter, y = difference)) +
  geom_line(colour = &amp;quot;yellow&amp;quot;) +
  theme_classic() +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.title.x = element_blank(),
        panel.background = element_rect(fill = &amp;quot;#3A9425&amp;quot;),
        axis.line = element_line(colour = &amp;quot;#EE4000&amp;quot;)) +
  annotate(&amp;quot;label&amp;quot;, label = &amp;quot;1989&amp;quot;, x = 2, y = -0.7, colour = &amp;quot;#EE4000&amp;quot;) +
  annotate(&amp;quot;label&amp;quot;, label = &amp;quot;2016&amp;quot;, x = 47, y = -0.7, colour = &amp;quot;#EE4000&amp;quot;) +
  geom_hline(yintercept = 0, linetype = 2, colour = &amp;quot;#EE4000&amp;quot;) +
  annotation_custom(g, xmin=0, xmax=7, ymin=0.5, ymax=0.95)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/brad_pitt_movies.htmlfigures/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Hmm, he’s had a fairly erratic career in terms of movie ratings. Looking at the relationship between ratings and time, there’s a bit of an improvement, and certainly less train-wrecks, but the improvement is not massive. Maybe he didn’t start off so bad, after all.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(movies, aes(x = YEAR, y = RATING)) +
  geom_point(colour = &amp;quot;yellow&amp;quot;) +
  geom_smooth(method = &amp;quot;lm&amp;quot;, colour = &amp;quot;#EE4000&amp;quot;) +
  theme(panel.background = element_rect(fill = &amp;quot;#3A9425&amp;quot;),
        axis.line = element_line(colour = &amp;quot;#EE4000&amp;quot;)) +
  annotation_custom(g, xmin=2013, xmax=2016, ymin=0.01, ymax=0.25)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/brad_pitt_movies.htmlfigures/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So what was Mr. Pitt’s worst film?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;movies %&amp;gt;% arrange(RATING) %&amp;gt;% head(n = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   RATING      TITLE            CREDIT YEAR difference date_counter
## 1   0.04 Cool World Det. Frank Harris 1992      -0.79            5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Wow! 0.04!! I have never seen ‘Cool World’, but it can’t be that bad…can it?&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://i.imgur.com/2oUrH2J.jpg&#34; /&gt; &lt;br&gt;&lt;/p&gt;
&lt;p&gt;Hmm, maybe it can…&lt;/p&gt;
&lt;p&gt;And his best?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;movies %&amp;gt;% arrange(desc(RATING)) %&amp;gt;% select(RATING, TITLE) %&amp;gt;% head(n = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   RATING            TITLE
## 1   0.96 12 Years a Slave&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;12 Years a Slave. Well, that was a fine movie, and I thought Fassbender was fantastic, as usual. Which makes me think about how Brad Pitt compares to other actors of his generation. Fassbender might be a comparative late starter, but let’s see how he and some others (George Clooney, Leonardo DiCaprio, Daniel Day-Lewis, Jamie Foxx and Tom Cruise) compare to Brad Pitt in terms of ratings (earnings might be another interesting comparison). We can use the work we did earlier as an outline for a function to do the same as we did for Bradley for all these male actors, adding a column with a name of the actor.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(reshape)

actors &amp;lt;- c(&amp;quot;george_clooney&amp;quot;, &amp;quot;leonardo_di_caprio&amp;quot;, &amp;quot;daniel_daylewis&amp;quot;,
            &amp;quot;jamie_foxx&amp;quot;, &amp;quot;tom_cruise&amp;quot;, &amp;quot;michael_fassbender&amp;quot;)

base_url &amp;lt;- &amp;quot;https://www.rottentomatoes.com/celebrity/&amp;quot;
movie_list &amp;lt;- list()

for(actor in actors){
  url &amp;lt;- paste0(base_url, actor, &amp;quot;/&amp;quot;)
  page &amp;lt;- read_html(url)
  tb_x &amp;lt;- html_nodes(page, css = &amp;quot;#filmographyTbl&amp;quot;)
  tb &amp;lt;- html_table(tb_x)
  movie &amp;lt;- tb[[1]]
  movie_list[[actor]] &amp;lt;- movie
  movie_list[[actor]]$ACTOR &amp;lt;- actor
  names(movie_list[actor]) &amp;lt;- actor
}

all_actors &amp;lt;- merge_all(movie_list)

all_actors &amp;lt;- all_actors %&amp;gt;%
  mutate(CREDIT = gsub(&amp;quot;\\r\\n&amp;quot;, &amp;quot;&amp;quot;, CREDIT)) %&amp;gt;%
  filter(RATING != &amp;quot;No Score Yet&amp;quot;,
         CREDIT %ni% c(&amp;quot;Producer&amp;quot;, &amp;quot;Executive Producer&amp;quot;,
                       &amp;quot;Director Producer&amp;quot;)) %&amp;gt;%
  mutate(RATING = gsub(&amp;quot;%&amp;quot;, &amp;quot;&amp;quot;, RATING),
         RATING = as.numeric(RATING),
         RATING = RATING/100,
         ACTOR = gsub(&amp;quot;_&amp;quot;, &amp;quot; &amp;quot;, ACTOR))

movies &amp;lt;- movies %&amp;gt;%
  mutate(ACTOR = &amp;quot;brad pitt&amp;quot;)

all_actors &amp;lt;- full_join(all_actors, movies) %&amp;gt;%
  select(-c(difference, date_counter))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So, now that we’ve done all that, let’s have a look at how these chaps compare!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(all_actors, aes(y = RATING, x = ACTOR)) +
  geom_boxplot(fill = &amp;quot;#EE4000&amp;quot;, colour = &amp;quot;yellow&amp;quot;) +
  theme(panel.background = element_rect(fill = &amp;quot;#3A9425&amp;quot;),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.line = element_line(colour = &amp;quot;#EE4000&amp;quot;),
        axis.text.x = element_text(angle = 15, hjust = 1,
                                   colour = &amp;quot;#EE4000&amp;quot;),
        axis.text.y = element_text(colour = &amp;quot;#EE4000&amp;quot;),
        axis.ticks = element_line(colour = &amp;quot;#EE4000&amp;quot;),
        axis.title = element_text(colour = &amp;quot;#EE4000&amp;quot;)) +
  annotation_custom(g, xmin=1.5, xmax=2.5, ymin=0.01, ymax=0.25)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/brad_pitt_movies.htmlfigures/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Not surprisingly, the three-time Best Actor Oscar winner Daniel Day-Lewis has a notably different profile. He doesn’t make many bad movies, that’s for sure (there’s nothing under the tomato image). Poor Jamie Foxx, on the other hand, has made quite a few more stinkers. Perhaps opportunities were harder to come by for the only black actor in the group, perhaps not.&lt;/p&gt;
&lt;p&gt;So after all that, what do we think of Meister Pitt? He compares very favourably to some of his peers, with maybe only Fassbender and Day-Lewis on a different level. Still, though, not bad, Mr. Pitt. Even after Mr. and Mrs. Smith :wink:&lt;/p&gt;
&lt;p&gt;&lt;link rel=&#34;image_src&#34; href=&#34;http://i.imgur.com/yBsAkLa.png?1&#34; /&gt;&lt;/p&gt;


&lt;!-- BLOGDOWN-HEAD




/BLOGDOWN-HEAD --&gt;
</description>
    </item>
    
    <item>
      <title>Tips and Tricks for R Markdown html</title>
      <link>/background-image-rmarkdown.html</link>
      <pubDate>Mon, 02 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>/background-image-rmarkdown.html</guid>
      <description>&lt;!-- BLOGDOWN-BODY-BEFORE

/BLOGDOWN-BODY-BEFORE --&gt;

&lt;p&gt;Here are a couple of little tips and tricks that I’ve picked up for use with RMarkdown html documents (including presentations and notebooks). This post is aimed at the R user who doesn’t know much, if anything, about html and css.&lt;/p&gt;
&lt;div id=&#34;background-images&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Background images&lt;/h2&gt;
&lt;p&gt;Sometimes it’s useful (or just nice) to have a background image of some sort in a presentation or notebook. This could be the logo of your university or company, for example. To do this for a R Markdown document, you will need to do three things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;create a separate .css file,&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;have/create an image, made suitably transparent,&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;change the YAML in the R Markdown document.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can create a css file in any text editor. In this example I’m calling it ‘custom.css’. Include these lines (my image is called &lt;code&gt;results.jpg&lt;/code&gt;):&lt;/p&gt;
&lt;pre class=&#34;css&#34;&gt;&lt;code&gt;body{
   background-image: url(&amp;#39;results.jpg&amp;#39;);
   min-height: 500px;
    /* Set background image to fixed (don&amp;#39;t scroll along with the page) */
    background-attachment: fixed;
    background-position: right top;
    /* Set the background image to no repeat */
    background-repeat: no-repeat;
    /* Scale the background image to be as large as possible */
    background-size: cover;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The image itself will need to be quite transparent. You can do that with imagemagick. On a mac terminal, the command is:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;convert IMAGE -fill white -colorize 50% NEW_IMAGE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After this, we just need to change our YAML at the top of the R Markdown document like so:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;---
title: &amp;quot;R Notebooks&amp;quot;
output:
  html_notebook:
    css: custom.css
---&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You’ll have something interesting like this:&lt;/p&gt;
&lt;p&gt;&lt;img src = &#39;http://i.imgur.com/slwkLCg.png&#39;&gt;&lt;/p&gt;
&lt;p&gt;This image could of course be anything, like a company logo, for example. You could also leave a large portion of it white to place the image in the corner or side of the screen.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;two-columns&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Two columns&lt;/h2&gt;
&lt;p&gt;Another useful thing that we can do with css is create two columns, particularly useful in a presentation. In order to do that, add the following lines to the css file you’re using:&lt;/p&gt;
&lt;pre class=&#34;css&#34;&gt;&lt;code&gt;#left {
  left:-8.33%;
  text-align: left;
  float: left;
  width:50%;
  z-index:-10;
}

#right {
  left:31.25%;
  top: 75px;
  float: right;
  text-align: right;
  z-index:-10;
  width:50%;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When you want to use these columns in your R Markdown document, use them like so, with a bit of html:&lt;/p&gt;
&lt;pre class=&#34;html&#34;&gt;&lt;code&gt;&amp;lt;div id=&amp;quot;left&amp;quot;&amp;gt;
  #content
&amp;lt;/div&amp;gt;
&amp;lt;div id=&amp;quot;right&amp;quot;&amp;gt;
  #content
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For example, this code:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;lt;div id=&amp;quot;left&amp;quot;&amp;gt;
$$y_i \backsim Normal(\mu_i, \sigma)$$
$$\mu_i = \alpha + \beta x_i$$
$$\sigma \backsim Uniform(0, 1)$$
$$\beta \backsim Normal(0, 10)$$
$$\alpha \backsim Normal(0, 10)$$
&amp;lt;/div&amp;gt;

&amp;lt;div id=&amp;quot;right&amp;quot;&amp;gt;
- `Likelihood`
- `Linear model`
- `sigma prior`
- `beta prior`
- `alpha prior`
&amp;lt;/div&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;produces this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#39;http://i.imgur.com/Kpvf8mX.png&#39;&gt;&lt;/p&gt;
&lt;p&gt;Likewise, an external css file can be used to change defaults. I think the default R code snippet text size is a little small in the R Notebooks, as is all the text in an R Notebook if you’re using them for presentations. You can easily change the defaults by putting:&lt;/p&gt;
&lt;pre class=&#34;css&#34;&gt;&lt;code&gt;body{ /* Normal  */
   font-size: 16px;
}
code.r{ /* Code block */
  font-size: 14px;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;in the css file, which will make the normal text and the R code text bigger. If you want to make all the text slightly bigger in the entire document without an external css file, you can just put &lt;font&gt; tags at the start and end of the R Markdown document:&lt;/p&gt;
&lt;pre class=&#34;html&#34;&gt;&lt;code&gt;&amp;lt;font size=6&amp;gt;
# content
&amp;lt;/font&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Similarly, bits of html can come in handy when you want to change little elements of the document. &lt;code&gt;&amp;lt;br&amp;gt;&lt;/code&gt; will give you a vertical space, and using &lt;code&gt;&amp;lt;bdi&amp;gt;&lt;/code&gt; tags can be useful for changing the style of particular words, especially useful for words that are presented as ‘code’ in back ticks. For example:&lt;/p&gt;
&lt;pre class=&#34;html&#34;&gt;&lt;code&gt;&amp;lt;bdi style=&amp;quot;color:#36648B&amp;quot;&amp;gt;`variable_1`&amp;lt;/bdi&amp;gt;.

&amp;lt;bdi style=&amp;quot;font-size:70%;&amp;quot;&amp;gt;(**`?dplyr::select`**)&amp;lt;/bdi&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;will make ‘variable_1’ appear in code-style text and be blue (&lt;bdi style=&#34;color:#36648B&#34;&gt;&lt;code&gt;variable_1&lt;/code&gt;&lt;/bdi&gt;), whereas ‘?dplyr::select’ will be bold and 70% of the size that it would otherwise be. (&lt;bdi style=&#34;font-size:70%;&#34;&gt;(&lt;strong&gt;&lt;code&gt;?dplyr::select&lt;/code&gt;&lt;/strong&gt;)&lt;/bdi&gt;)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;revealjs-logos&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;revealjs logos&lt;/h2&gt;
&lt;p&gt;The image of the two columns above was part of a revealjs presentation done in R Markdown. revealjs gives you really slick options for presentations, but can be a lot of extra work in terms of customizing the output. Logos, for example, which are so common (and necessary) in presentations, are not included by default and can be tricky and annoying to include.&lt;/p&gt;
&lt;p&gt;We can get what we want with a little html and some YAML options. In the example below, I used an external html file called &lt;code&gt;Logo_prefix.html&lt;/code&gt;, which is referenced in the &lt;code&gt;includes:&lt;/code&gt; section of the YAML header. The html file contains the following, which uses an image called &lt;code&gt;logo.png&lt;/code&gt;. The size can be adjusted using the &lt;code&gt;style=&amp;quot;&amp;quot;&lt;/code&gt; part below.&lt;/p&gt;
&lt;pre class=&#34;html&#34;&gt;&lt;code&gt;&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html&amp;gt;
 &amp;lt;div class=&amp;quot;bottombar&amp;quot;&amp;gt;
    &amp;lt;h1 class=&amp;quot;title&amp;quot;&amp;gt;&amp;lt;/h1&amp;gt;&amp;lt;image class=&amp;quot;logo&amp;quot; src=&amp;quot;logo.png&amp;quot; style=&amp;quot;width:180px; height:85px;&amp;quot;&amp;gt;
&amp;lt;/div&amp;gt;
&amp;lt;/html&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And the RMarkdown YAML I used (for a course in statistics in R in Portuguese; the 2017-02-01 is a nice trick to put the current date on the presentation):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;---
title: &amp;quot;Introdução a estatística no `R`, Dia 2&amp;quot;
author: &amp;quot;Robert McDonnell&amp;quot;
date: &amp;quot;`r Sys.Date()`&amp;quot;
output:
  revealjs::revealjs_presentation:
    theme: sky
    highlight: pygments
    css: custom.css
    includes:
      before_body: Logo_prefix.html
---&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This includes a small logo in the upper right corner of every slide. To get this to work properly, you will need to dig into the css of the particular revealjs theme that you are using (here I’m using sky), I can’t even remember exactly how I did that… like I said, customizing revealjs can be annoying.&lt;/p&gt;
&lt;/div&gt;


&lt;!-- BLOGDOWN-HEAD




/BLOGDOWN-HEAD --&gt;
</description>
    </item>
    
    <item>
      <title>Make a colour table in R with ggplot2</title>
      <link>/colour-table.html</link>
      <pubDate>Thu, 29 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>/colour-table.html</guid>
      <description>&lt;!-- BLOGDOWN-BODY-BEFORE

/BLOGDOWN-BODY-BEFORE --&gt;

&lt;p&gt;I loved &lt;a href=&#34;https://github.com/hdugan/rColorTable/blob/master/rColorTable.R&#34;&gt;this&lt;/a&gt; R script from hdugan when I first saw it a while ago. The script makes a 2-page pdf of all the colors available in R, using R. Nice.&lt;/p&gt;
&lt;p&gt;The other day, I thought about making a tidyverse version of it, using dplyr to get the data ready and ggplot2 to visualize it. I won’t for a second pretend that this code is as short and tidy as the original, and in fact it may be a good example of when base R can be really useful, but anyway here it is. (The pdf it produces follows.) The table shows all the colours available in R, from the base colour on the left hand side, and then a scale of increasingly darker hues (from 1 to 4) for colours that have them. The basic idea was to create six plots and place them side by side using &lt;code&gt;cowplot::plot_grid()&lt;/code&gt;. (&lt;code&gt;grid.arrange()&lt;/code&gt; from the gridExtra package was a little less customizable.) So here you go: a tidyverse R Colour Table. (Using RColorBrewer you could add some purdy palette extensions). It’s a one-page pdf, you could split into smaller images by subsetting the data and so on.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# R colors minus 100 shades of grey

library(stringr)
library(tidyverse)


# get &amp;#39;data&amp;#39;:

colour &amp;lt;- data_frame(colours = colors()) %&amp;gt;%
  filter(!grepl(&amp;quot;gray&amp;quot;, colours),
         !grepl(&amp;quot;grey&amp;quot;, colours)) %&amp;gt;%
  mutate(general_colour = gsub(&amp;quot;[0-9]&amp;quot;, &amp;quot;&amp;quot;, colours),
         c1 = ifelse(grepl(&amp;quot;1&amp;quot;, colours), 1, 0),
         c2 = ifelse(grepl(&amp;quot;2&amp;quot;, colours), 1, 0),
         c3 = ifelse(grepl(&amp;quot;3&amp;quot;, colours), 1, 0),
         c4 = ifelse(grepl(&amp;quot;4&amp;quot;, colours), 1, 0)) %&amp;gt;%
  select(-1) %&amp;gt;%
  group_by(general_colour) %&amp;gt;%
  summarise_each(funs(sum)) %&amp;gt;%
  ungroup() %&amp;gt;%
  mutate(c1 = ifelse(grepl(1, c1), paste0(general_colour, c1), NA),
         c2 = ifelse(grepl(1, c2), paste0(general_colour, &amp;quot;2&amp;quot;), NA),
         c3 = ifelse(grepl(1, c3), paste0(general_colour, &amp;quot;3&amp;quot;), NA),
         c4 = ifelse(grepl(1, c4), paste0(general_colour, &amp;quot;4&amp;quot;), NA),
         c1 = ifelse(is.na(c1), general_colour, c1),
         c2 = ifelse(is.na(c2), general_colour, c2),
         c3 = ifelse(is.na(c3), general_colour, c3),
         c4 = ifelse(is.na(c4), general_colour, c4))


## create six plots:
# Just the names, by setting alpha to 0:
g0 &amp;lt;- ggplot(colour, aes(x = general_colour)) +
  geom_bar(position = &amp;quot;stack&amp;quot;, alpha = 0) +
  coord_flip() +
  theme_minimal() +
  theme(legend.position = &amp;quot;none&amp;quot;) +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank(),
        axis.title.x = element_blank(), panel.grid = element_blank(),
        axis.title.y = element_blank())

g &amp;lt;- ggplot(colour, aes(x = general_colour, color = general_colour,
                   fill = general_colour)) +
  geom_bar(position = &amp;quot;stack&amp;quot;) +
  coord_flip() +
  scale_color_manual(values = colour$general_colour) +
  scale_fill_manual(values = colour$general_colour) +
  theme_minimal() +
  theme(legend.position = &amp;quot;none&amp;quot;) +
  theme(axis.text = element_blank(), axis.ticks = element_blank(),
        axis.title = element_blank(), panel.grid = element_blank())

g_1 &amp;lt;- ggplot(colour, aes(x = c1, color = c1,
                        fill = c1)) +
  geom_bar(position = &amp;quot;stack&amp;quot;) +
  coord_flip() +
  scale_color_manual(values = colour$c1) +
  scale_fill_manual(values = colour$c1) +
  theme_minimal() +
  theme(legend.position = &amp;quot;none&amp;quot;) +
  theme(axis.text = element_blank(), axis.ticks = element_blank(),
        axis.title = element_blank(), panel.grid = element_blank())

g_2 &amp;lt;- ggplot(colour, aes(x = c2, color = c2,
                        fill = c2)) +
  geom_bar(position = &amp;quot;stack&amp;quot;) +
  coord_flip() +
  scale_color_manual(values = colour$c2) +
  scale_fill_manual(values = colour$c2) +
  theme_minimal() +
  theme(legend.position = &amp;quot;none&amp;quot;) +
  theme(axis.text = element_blank(), axis.ticks = element_blank(),
        axis.title = element_blank(), panel.grid = element_blank())

g_3 &amp;lt;- ggplot(colour, aes(x = c3, color = c3,
                        fill = c3)) +
  geom_bar(position = &amp;quot;stack&amp;quot;) +
  coord_flip() +
  scale_color_manual(values = colour$c3) +
  scale_fill_manual(values = colour$c3) +
  theme_minimal() +
  theme(legend.position = &amp;quot;none&amp;quot;) +
  theme(axis.text = element_blank(), axis.ticks = element_blank(),
        axis.title = element_blank(), panel.grid = element_blank())

g_4 &amp;lt;- ggplot(colour, aes(x = c4, color = c4,
                        fill = c4)) +
  geom_bar(position = &amp;quot;stack&amp;quot;) +
  coord_flip() +
  scale_color_manual(values = colour$c4) +
  scale_fill_manual(values = colour$c4) +
  theme_minimal() +
  theme(legend.position = &amp;quot;none&amp;quot;) +
  theme(axis.text = element_blank(), axis.ticks = element_blank(),
        axis.title = element_blank(), panel.grid = element_blank())

library(cowplot)
# Here I create a pdf, but you can just as easily create a
# png or a jpeg.

pdf(file = &amp;quot;color_chart_dplyr.pdf&amp;quot;, height = 35, width = 8)
plot_grid(g0, g, g_1, g_2, g_3, g_4, align = &amp;quot;h&amp;quot;, ncol = 6,
          rel_widths = c(.75, 1.05, 1.05, 1.05, 1.05, 1.05))
dev.off()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src = &#34;http://i.imgur.com/JVXhXyj.png&#34;&gt;&lt;/p&gt;


&lt;!-- BLOGDOWN-HEAD




/BLOGDOWN-HEAD --&gt;
</description>
    </item>
    
    <item>
      <title>Suicides in Ireland</title>
      <link>/suicides-in-ireland.html</link>
      <pubDate>Wed, 21 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>/suicides-in-ireland.html</guid>
      <description>&lt;!-- BLOGDOWN-BODY-BEFORE

/BLOGDOWN-BODY-BEFORE --&gt;

&lt;p&gt;The Irish radio station newstalk published &lt;a href=&#34;https://www.facebook.com/newstalkfm/videos/10155656582617907/&#34;&gt;this video&lt;/a&gt; the other day, in which director and actor Terry McMahon spoke out against the austerity programme running in Ireland since the aftermath of the financial crisis in 2008. Leaving aside his conflation of any type of business activity with immorality, McMahon claimed that “austerity is murder” and detailed some alarming facts about suicide numbers in Ireland, clearly linking the two (i.e., austerity = more suicide).&lt;/p&gt;
&lt;p&gt;Even though I &lt;strong&gt;really&lt;/strong&gt; hated the fact that irresponsible banks were socialized for their own recklessness, while the rest of the population suffered tax hikes and cuts to important services, there was something about this video that irritated me. McMahon states that we have let down “the best” of our society, being Padraig Pearse and his comrades of the 1916 Rising (which did not have popular support and took most Irish people by complete surprise). How, exactly? By not sticking to De Valera’s impoverishing mercantilism or by not leaving women in their constitutional place, the home? Leaving aside these irritations, I decided to take a closer look at the suicide claims made by McMahon. These data are publicly available, from the &lt;a href=&#34;http://nsrf.ie/statistics/suicide/&#34;&gt;National Suicide Research Foundation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We can do all this quite easily in R:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rvest)
library(dplyr)
library(ggplot2)
library(lubridate)
page &amp;lt;- read_html(&amp;quot;http://nsrf.ie/statistics/suicide/&amp;quot;)

table &amp;lt;- html_nodes(page,
                    css = &amp;quot;#ac_3163_collapse1 &amp;gt; div &amp;gt; table:nth-child(2)&amp;quot;)

table &amp;lt;- html_table(table)[[1]]

colnames(table) &amp;lt;- c(&amp;quot;Year&amp;quot;, &amp;quot;Total_number&amp;quot;, &amp;quot;Total_rate_per_100000&amp;quot;,
                     &amp;quot;Male_number&amp;quot;, &amp;quot;Male_rate_per_100000&amp;quot;,
                     &amp;quot;Female&amp;quot;, &amp;quot;Female_rate_per_100000&amp;quot;)

ggplot(table, aes(x = Year)) +
  geom_line(aes(y = Male_rate_per_100000), colour = &amp;quot;navy&amp;quot;) +
  geom_line(aes(y = Female_rate_per_100000), colour = &amp;quot;goldenrod2&amp;quot;) +
  scale_x_continuous(breaks = c(2001, 2004, 2007, 2010, 2013, 2015)) +
  theme_classic() +
  labs(y = &amp;quot;Suicide Rate per 100,000&amp;quot;) +
  annotate(&amp;quot;label&amp;quot;, label = &amp;quot;Male&amp;quot;, x = 2002, y = 18) +
  annotate(&amp;quot;label&amp;quot;, label = &amp;quot;Female&amp;quot;, x = 2002, y = 6.5)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;./figs/suicides/unnamed-chunk-1-1.png&#34; alt=&#34;center&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;center&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Judging from 2001 onwards, suicide among males has in fact gone down, from highs in 2001 (22.4 per 100,000), 2004 (20.2; both years well before the austerity programme) and 20.2 per 100,000 in 2011, two years after the start of the austerity programme. After 2012, suicide among males thankfully declines by relatively quite a lot.&lt;/p&gt;
&lt;p&gt;Another of McMahon’s claims is that more people committed suicide in 2016 than died in the Easter Rising of 1916. I’m not quite sure where he got these statistics. The National Suicide Research Foundation has until 2015, while the Central Statistics Office has the first two quarters of 2016 available on its website (&lt;a href=&#34;http://www.cso.ie/en/releasesandpublications/ep/p-vs/vitalstatisticsfirstquarter2016/&#34;&gt;first&lt;/a&gt; and &lt;a href=&#34;http://www.cso.ie/en/releasesandpublications/ep/p-vs/vitalstatisticssecondquarter2016/&#34;&gt;second&lt;/a&gt;). According to these figures, there were 91 suicides in the first quarter and 75 in the second, being 166 in total. If we divide this number in two as our best guess for quarter 3, we get 83. People think that suicides go up at Christmas, but according to the website statnews.com, that is not &lt;a href=&#34;https://www.statnews.com/2015/12/30/suicides-rise-after-christmas/&#34;&gt;true&lt;/a&gt;. Well, even allowing for 100 suicides in the 4th quarter, we get 166 + 83 + 100 = 349 (keep in mind this is quite an inflated guess, something more realistic would be 166 + 75 + 75 = 316). According to &lt;a href=&#34;https://en.wikipedia.org/wiki/Easter_Rising&#34;&gt;Wikipedia&lt;/a&gt;, “almost 500 people were killed in the Easter Rising”. So McMahon is incorrect on this point.&lt;/p&gt;
&lt;p&gt;McMahon also said that during the last eight years of austerity more people have died by suicide in Ireland than died during the thirty-year-long troubles in Northern Ireland. A statistical breakdown of the deaths in the Troubles can be found &lt;a href=&#34;http://www.wesleyjohnston.com/users/ireland/past/troubles/troubles_stats.html&#34;&gt;here&lt;/a&gt;, which puts the total number of deaths at 3466. Using the data we got from the National Suicide Research Foundation:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(knitr)
kable(table[,1:3])&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;Year&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Total_number&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Total_rate_per_100000&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;2001&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;519&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;13.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;2002&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;478&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12.2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;2003&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;497&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;2004&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;493&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12.2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;2005&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;481&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11.6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;2006&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;460&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10.9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;2007&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;458&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10.6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;2008&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;506&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11.4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;2009&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;552&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12.4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;2010&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;495&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;2011&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;554&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;2012&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;541&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11.8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;2013&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;487&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10.6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;2014&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;459&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;2015&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;451&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9.7&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Summing these numbers for the years 2009 to 2015 (the austerity programme) is straightforward:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;table %&amp;gt;%
  select(Year, Total_number) %&amp;gt;%
  filter(Year &amp;gt; 2008, Year &amp;lt;= 2015) %&amp;gt;%
  summarise(total = sum(Total_number))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;##   total
## 1  3539&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here, McMahon is correct, which is shocking and sad (remember, we didn’t include 2016), but to actually tie these suicides to austerity causally, we would need a much more sophisticated approach. (Likewise with the decline since 2001.)&lt;/p&gt;
&lt;p&gt;The point of this post is not to argue for the austerity programme (the banks should have paid for their mistakes and should not have been rescued. If they truly were “too big to fail” in terms of the Irish economy, then we could have rescued them and then liquidated them, returning the money to the state.) It is also not to argue for/against NAMA. Occupying a building for a few weeks puts the debate at centre-stage, for which McMahon and co. should be congratulated. But if we are to have a debate about the problems introduced by austerity, we should at least get the numbers right. Suicide for both men and women has declined in recent years in Ireland, and more people died in the Easter Rising than by suicide in 2016. Yes, more people died by suicide since 2009 than in the Troubles, which is tragic. I’ll leave McMahon’s bizarre eulogies for an Ireland of poets and warriors, opposed to any type of commerce, aside (what finances the arts?). The crony capitalism that flourished in Ireland during the Bertie Ahern years damaged the country, no doubt. But no need to hark back to a simpler, poorer, time: just fix the mess and jail those responsible (including Ahern). But saying “austerity is murder” and evoking the ‘heroes’ of 1916 is just pretty reckless, in my view.&lt;/p&gt;


&lt;!-- BLOGDOWN-HEAD




/BLOGDOWN-HEAD --&gt;
</description>
    </item>
    
    <item>
      <title>Theme-Specific Voting in the European Parliament</title>
      <link>/meps.html</link>
      <pubDate>Thu, 20 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>/meps.html</guid>
      <description>&lt;!-- BLOGDOWN-BODY-BEFORE

/BLOGDOWN-BODY-BEFORE --&gt;

&lt;p&gt;Since it’s &lt;a href=&#34;http://ec.europa.eu/eurostat/web/ess/european-statistics-day&#34;&gt;European Statistics Day&lt;/a&gt;, I thought I would make a quick post showing how to utilise some of the data that we have on the European Union in R. In particular, I will use European Parliament voting data from Simon Hix’s &lt;a href=&#34;http://personal.lse.ac.uk/hix/HixNouryRolandEPdata.HTM&#34;&gt;website&lt;/a&gt;. The data is freely available, so by copying and pasting the code below, you will be able to recreate the analysis I’ve done here.&lt;/p&gt;
&lt;p&gt;We’re going to be using &lt;a href=&#34;http://mc-stan.org/&#34;&gt;Stan&lt;/a&gt; to make theme-specific ideal points for members of the European Parliament. You will need to install Stan and a C++ compiler to replicate the analysis.&lt;/p&gt;
&lt;p&gt;First, let’s load the R packages that we’re going to use. If you don’t have any of these, you will need to install them first, using either &lt;code&gt;install.packages(&amp;quot;name of package&amp;quot;)&lt;/code&gt; or by means of the ‘install’ button on the Packages window of the RStudio IDE.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(data.table)
library(tidyverse)
library(dtplyr)
library(rstan)
library(stringi)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After you download the data from Hix’s website, we can import it into R. I will then merge everything together.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rm(list = ls())

eu4 &amp;lt;- as_tibble(fread(&amp;quot;~/Downloads/ep6/RCVS2004Full.csv&amp;quot;, header=T))
eu5 &amp;lt;- as_tibble(fread(&amp;quot;~/Downloads/ep6/RCVS2005Full.csv&amp;quot;, header = T))
eu6 &amp;lt;- as_tibble(fread(&amp;quot;~/Downloads/ep6/RCVS2006Full.csv&amp;quot;, header = T))
eu7 &amp;lt;- as_tibble(fread(&amp;quot;~/Downloads/ep6/RCVS2007Full.csv&amp;quot;, header = T))
eu8 &amp;lt;- as_tibble(fread(&amp;quot;~/Downloads/ep6/RCVS2008Full.csv&amp;quot;, header = T))
eu9 &amp;lt;- as_tibble(fread(&amp;quot;~/Downloads/ep6/RCVS2009Full.csv&amp;quot;, header = T))

eu &amp;lt;- eu4 %&amp;gt;%
  full_join(eu5) %&amp;gt;%
  full_join(eu6) %&amp;gt;%
  full_join(eu7) %&amp;gt;%
  full_join(eu8) %&amp;gt;%
  full_join(eu9) %&amp;gt;%
  select(-V1) %&amp;gt;%
  rename(voter = `Vote ID`) %&amp;gt;%
  mutate(voter = stri_trans_general(voter, &amp;quot;Latin-ASCII&amp;quot;))

rm(eu4, eu5, eu6, eu7, eu8, eu9)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we have a data frame of each of the 940 legislators in the database, and their votes on 6200 votes. Next we’ll create some id variables that we will use when we send the data to Stan.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;EU &amp;lt;- gather(eu, vote_id, vote, `1`:`6200`) %&amp;gt;%
  mutate(vote_id = as.numeric(vote_id),
         voter_id = as.numeric(as.factor(voter)))
head(EU)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we have each voter (the M.E.P., &lt;code&gt;voter&lt;/code&gt;), the id of the bill being voted on (&lt;code&gt;vote_id&lt;/code&gt;), how the individual voted (&lt;code&gt;vote&lt;/code&gt;) and the id of each voter. In these data, 1 is a ‘yes’ vote, while 0 is ‘no’. The full list from Hix’s website contains the following info:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;The codes for the MEP vote decisions are as follows:
EP1, EP2 and EP5: 1=Yes, 2=No, 3=Abstain, 4=Present but did not vote, 0=Absent, 5=Not an MEP
EP3 and EP4: 1 = Yes, 2 = No, 3 = Abstain, 4 = Present but did not vote, 0 = either Absent or Not an MEP&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Hix &amp;amp; co. also provide us with information on the specific policy area for each vote. We can import it, tidy it up a little and merge it to the data we have.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;theme &amp;lt;- as_tibble(fread(&amp;quot;~/Downloads/ep6/vc.csv&amp;quot;))

theme &amp;lt;- theme %&amp;gt;%
  rename(vote_id = `Vote Id`) %&amp;gt;%
  select(vote_id, Title, `Policy Area`, Result) %&amp;gt;%
  rename(topic = `Policy Area`) %&amp;gt;%
  mutate(topic_id = as.numeric(as.factor(topic)))

rollcalls &amp;lt;- full_join(EU, theme) %&amp;gt;%
  mutate(vote = ifelse(vote==1, 1, ifelse(vote==0, 0, NA))) %&amp;gt;%
  filter(!is.na(vote))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we need to prepare the data for Stan. Our model is a basic &lt;a href=&#34;https://www.cs.princeton.edu/courses/archive/fall09/cos597A/papers/ClintonJackmanRivers2004.pdf&#34;&gt;2-parameter Item-Response theory model&lt;/a&gt; often used for &lt;a href=&#34;http://robertmyles.github.io/Bayesian-IRT-in-R-and-Stan.html&#34;&gt;creating ideal points&lt;/a&gt;. We write this in the Stan modelling language and save it as a string in R. In mathematical notation, the model is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_{ijk} = \beta_j \theta_{ik} - \alpha_j,\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;em&gt;i&lt;/em&gt; is an index of voters, &lt;em&gt;j&lt;/em&gt; an index of votes, and &lt;em&gt;k&lt;/em&gt; an index of topics. &lt;span class=&#34;math display&#34;&gt;\[\theta_{ik}\]&lt;/span&gt; is our main object of interest: the ideal point of MEP &lt;em&gt;i&lt;/em&gt; on topic &lt;em&gt;k&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;For those not familiar with Stan, the following Stan code has a &lt;code&gt;data&lt;/code&gt; block, in which we declare what our variables are and their type (these are created in the section after). Then we have a parameters block where we declare our parameters.&lt;/p&gt;
&lt;p&gt;Lastly, we have the model block where we have our model and the priors for each parameter. In an IRT model like this, we need to constrain the ideal points of at least 2 legislators. Since I am not an expert on these MEPs, I am just going to do this for the first two in the database (&lt;code&gt;theta[1]&lt;/code&gt; and &lt;code&gt;theta[2]&lt;/code&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mep_model &amp;lt;- &amp;quot;
data {
  int&amp;lt;lower=1&amp;gt; J;               //MEPs
  int&amp;lt;lower=1&amp;gt; M;               //Proposals
  int&amp;lt;lower=1&amp;gt; K;               //no. of topics
  int&amp;lt;lower=1&amp;gt; N;               //no. of observations
  vector[K] m0;                 // prior mean for theta
  cov_matrix[K] M0;             // prior covar. for theta
  int&amp;lt;lower=1, upper=J&amp;gt; j[N];   //MEP for observation n
  int&amp;lt;lower=1, upper=M&amp;gt; m[N];   //proposal for observation n
  int&amp;lt;lower=1, upper=K&amp;gt; k[N];   //topic for observation n
  int&amp;lt;lower=0, upper=1&amp;gt; Y[N];   //vote of observation n
}
parameters {
  real alpha[M];
  real beta[M];
  vector[K] theta[J];
}
model {
  beta ~ normal(0, 10);
  alpha ~ normal(0, 10);
  for (n in 1:N)
  Y[n] ~ bernoulli_logit(theta[j[n], k[n]]*beta[m[n]] - alpha[m[n]]);
  theta ~ multi_normal(m0, M0);
  theta[1,1] ~ normal(1, .01);
  theta[2,1] ~ normal(-1, .01);
}&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Above, we have variables declared in our Stan model. Here, I define these objects in R. All of this then goes as a list to Stan.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rstan)

N &amp;lt;- nrow(rollcalls)
M &amp;lt;- max(rollcalls$vote_id)
K &amp;lt;- max(rollcalls$topic_id)
J &amp;lt;- max(rollcalls$voter_id)
Y &amp;lt;- rollcalls$vote
m &amp;lt;- rollcalls$vote_id
k &amp;lt;- rollcalls$topic_id
j &amp;lt;- rollcalls$voter_id

# Mean and Covariances for theta
m0 &amp;lt;- rep(0, times=K)
M0 &amp;lt;- matrix(0, K, K)
diag(M0) &amp;lt;- 1

stan_data &amp;lt;- list(J=J, N=N, M=M, j=j,
                  Y=Y, m=m, K=K, k=k,
                  m0=m0, M0=M0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we run our model with Stan. Here I use Stan’s new &lt;a href=&#34;&#34;&gt;ADVI&lt;/a&gt; feature, but the Stan folks don’t recommend this for inference. However, for a blog post it’s okay :smile:.&lt;/p&gt;
&lt;p&gt;ADVI is much faster than the already comparatively fast NUTS sampling that Stan does. Here we have a lot of data, though, so this next part will take &lt;strong&gt;a few hours&lt;/strong&gt; to run. If you don’t fancy waiting so long, subset the data (maybe choose just one year) and run the Stan code on the smaller dataset.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Stan_Model &amp;lt;- stan_model(model_name = &amp;quot;meps&amp;quot;, model_code = mep_model)

Res1 &amp;lt;- vb(Stan_Model, data = stan_data, seed = 1234,
          init = &amp;quot;random&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So one thing that we could do with the estimates from this model is plot the ideal points of an MEP as they vary over the themes that he/she voted on.&lt;/p&gt;
&lt;p&gt;What we will do is extract the elements of the summary that we want and then create the summary that we need to start making figures.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary &amp;lt;- list(summary(Res1, pars=&amp;quot;theta&amp;quot;))
summary &amp;lt;- summary[[1]][1]
summary &amp;lt;- as_data_frame(summary[[1]]) %&amp;gt;%
  mutate(names = theta_names,
         voters = rep(unique(rollcalls$voter), each=21),
         index = as.character(str_extract_all(names, &amp;quot;\\.[0-9]*$&amp;quot;)),
         index = gsub(&amp;quot;\\.&amp;quot;, &amp;quot;&amp;quot;, index),
         index = as.integer(index))

topics &amp;lt;- unique(rollcalls$topic)
index &amp;lt;- unique(summary$index)
topic_index &amp;lt;- tibble(topic = topics, index = index)

mep_summary &amp;lt;- full_join(summary, topic_index) %&amp;gt;%
  select(-c(names, index))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The following graphs are of Adamos Adamou and Filip Adwent, for the simple reason that they are the first names in the database. First, we create a plot for Adamou and then for Adwent, then we combine them. In the following code, I customize the font, but none of that is necessary.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;adamou &amp;lt;- mep_summary %&amp;gt;% filter(voters==&amp;quot;ADAMOU, Adamos&amp;quot;)


ggplot(adamou, aes(x = mean, y = topic)) +
  geom_segment(aes(yend = topic), color = &amp;quot;#104E8B&amp;quot;,
               xend = 0, alpha = 0.3) +
  geom_point(size = 4, color = &amp;quot;#104E8B&amp;quot;) + theme_bw() +
  theme(legend.position = &amp;quot;none&amp;quot;, axis.title.y = element_blank(),
        axis.title.x = element_text(family = &amp;quot;Georgia&amp;quot;, face=&amp;#39;bold&amp;#39;),
        axis.text.y = element_text(family = &amp;quot;Georgia&amp;quot;, size = 12),
        axis.text.x = element_text(family = &amp;quot;Georgia&amp;quot;, size = 12)) +
  xlab(&amp;quot;Ideal Points, Adamos Adamou&amp;quot;) +
  geom_vline(xintercept = 0, linetype = &amp;quot;dashed&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://i.imgur.com/C4zpATc.png&#34;&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;adwent &amp;lt;- mep_summary %&amp;gt;% filter(voters==&amp;quot;ADWENT, Filip&amp;quot;)


ggplot(adwent, aes(x = mean, y = topic)) +
  geom_segment(aes(yend = topic), color = &amp;quot;#8B1A1A&amp;quot;,
               xend = 0, alpha = 0.3) +
  geom_point(size = 4, color = &amp;quot;#8B1A1A&amp;quot;) + theme_bw() +
  theme(legend.position = &amp;quot;none&amp;quot;, axis.title.y = element_blank(),
        axis.title.x = element_text(family = &amp;quot;Georgia&amp;quot;, face=&amp;#39;bold&amp;#39;),
        axis.text.y = element_text(family = &amp;quot;Georgia&amp;quot;, size = 12),
        axis.text.x = element_text(family = &amp;quot;Georgia&amp;quot;, size = 12)) +
  xlab(&amp;quot;Ideal Points, Filip Adwent&amp;quot;) +
  geom_vline(xintercept = 0, linetype = &amp;quot;dashed&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://i.imgur.com/gKFgL5L.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;We can put these two together and see how they compare:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(adamou, aes(x = mean, y = topic)) +
  geom_segment(aes(yend = topic), color = &amp;quot;#104E8B&amp;quot;,
               xend = 0, alpha = 0.3) +
  geom_segment(data = adwent, aes(yend = topic),
               xend = 0, colour = &amp;quot;#8B1A1A&amp;quot;,
               alpha = 0.3) +
  geom_point(size = 4, color = &amp;quot;#104E8B&amp;quot;) + theme_bw() +
  theme(legend.position = &amp;quot;none&amp;quot;, axis.title.y = element_blank(),
        axis.title.x = element_text(family = &amp;quot;Georgia&amp;quot;, face=&amp;#39;bold&amp;#39;),
        axis.text.y = element_text(family = &amp;quot;Georgia&amp;quot;, size = 12),
        axis.text.x = element_text(family = &amp;quot;Georgia&amp;quot;, size = 12)) +
  xlab(&amp;quot;Ideal Points, Adamos Adamou &amp;amp; Filip Adwent&amp;quot;) +
  geom_point(data = adwent, aes(x = mean, y =topic),
             size = 4, color = &amp;quot;#8B1A1A&amp;quot;) +
  geom_vline(xintercept = 0, linetype = &amp;quot;dashed&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://i.imgur.com/kBq6WGv.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;And of course you can customise these ggplot figures any way you like.&lt;/p&gt;
&lt;p&gt;Happy European Statistics Day! :dancers:&lt;/p&gt;


&lt;!-- BLOGDOWN-HEAD




/BLOGDOWN-HEAD --&gt;
</description>
    </item>
    
    <item>
      <title>Map-making with R and electionsBR</title>
      <link>/electionsbr.html</link>
      <pubDate>Sun, 09 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>/electionsbr.html</guid>
      <description>&lt;!-- BLOGDOWN-BODY-BEFORE

/BLOGDOWN-BODY-BEFORE --&gt;

&lt;p&gt;For those interested in Brazilian politics, there’s a great new package called &lt;code&gt;electionsBR&lt;/code&gt; (those who understand Portuguese can find a post on it &lt;a href=&#34;http://fmeireles.com/blog/rstats/electionsbr-um-pacote-para-baixar-dados-eleitorais-do-tse&#34;&gt;here&lt;/a&gt;). This package takes data from the &lt;em&gt;Tribunal Superior Eleitoral&lt;/em&gt; and makes it available in a tidy format for users of R. Given my recent obsession with &lt;a href=&#34;http://robertmyles.github.io//re-creating-plots-from-the-economist-in-r.html&#34;&gt;map-making&lt;/a&gt;, I think it’s only natural I’d want to make maps of Brazil with this package.&lt;sup id=&#34;a1&#34;&gt;&lt;a href=&#34;#fn1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;So, what can we do with it? Well, how about a map of how Brazilians voted in the general election of 2014? To do this, we can use &lt;code&gt;electionsBR&lt;/code&gt; to get the election data, and a mixture of &lt;code&gt;tidyverse&lt;/code&gt; and some mapping and plotting packages:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(electionsBR)
library(ggmap)
library(rgdal)
library(stringi)
library(scales)
library(maptools)
library(RColorBrewer)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;vote_mun_zone_fed()&lt;/code&gt; function takes a single argument, &lt;code&gt;year&lt;/code&gt;, as an integer. There are quite a lot of data, so it takes a little while to download.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Mun &amp;lt;- vote_mun_zone_fed(2014)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once we have these data, we can use the &lt;code&gt;tidyverse&lt;/code&gt; to clean it up and organize it they way we want. I’m going to change the character encoding to ASCII, using the &lt;code&gt;stringi&lt;/code&gt; package, and select only the columns I need.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Mun &amp;lt;- Mun %&amp;gt;%
  select(SIGLA_UF, DESCRICAO_CARGO, CODIGO_MUNICIPIO, TOTAL_VOTOS,
         NUMERO_CAND, NOME_MUNICIPIO, NUM_TURNO, SIGLA_PARTIDO) %&amp;gt;%
  mutate(NOME_MUNICIPIO = stri_trans_general(NOME_MUNICIPIO, &amp;quot;Latin-ASCII&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;One interesting thing we could do with this dataset is map the percentage of the electorate that voted for Dilma. We’ll need shapefiles for Brazil, which you can get from &lt;a href=&#34;http://www.gadm.org/country&#34;&gt;gadm.org&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We’ll also need to isolate the vote for Dilma and then calculate the proportion in each municipality that voted for her. There were also two rounds of voting, so we can show each one. The code below does this for the first round, to do the same thing for the second round, we just change the first call to &lt;code&gt;filter&lt;/code&gt; to &lt;code&gt;NUM_TURNO == 2&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Pres1 &amp;lt;- Mun %&amp;gt;%
  filter(DESCRICAO_CARGO == &amp;quot;PRESIDENTE&amp;quot;, NUM_TURNO == 1,
         SIGLA_UF != &amp;quot;ZZ&amp;quot;) %&amp;gt;%
  group_by(NUMERO_CAND, CODIGO_MUNICIPIO) %&amp;gt;%
  mutate(SUM = sum(TOTAL_VOTOS)) %&amp;gt;%
  distinct(CODIGO_MUNICIPIO, .keep_all=T) %&amp;gt;%
  ungroup() %&amp;gt;%
  group_by(CODIGO_MUNICIPIO) %&amp;gt;%
  mutate(PERC = TOTAL_VOTOS/sum(TOTAL_VOTOS)*100) %&amp;gt;%
  arrange(SIGLA_UF, NOME_MUNICIPIO) %&amp;gt;%
  ungroup() %&amp;gt;%
  filter(NUMERO_CAND == 13)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we read in our shape files. We have some work to do to tidy up the names of the municipalities and to correct for coding errors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;BRmap &amp;lt;- readOGR(dsn = &amp;quot;BRA_adm_shp&amp;quot;, layer = &amp;quot;BRA_adm3&amp;quot;, verbose = FALSE)
BRmap@data$NAME_2 &amp;lt;- BRmap@data$NAME_2 %&amp;gt;%
  as.character() %&amp;gt;%
  stri_trans_general(&amp;quot;Latin-ASCII&amp;quot;) %&amp;gt;%
  toupper()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s see what municipalities are missing from our &lt;code&gt;electionsBR&lt;/code&gt; municipality data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;#39;%ni%&amp;#39; &amp;lt;- Negate(&amp;#39;%in%&amp;#39;)

unique(BRmap@data$NAME_2[which(BRmap@data$NAME_2 %ni% Mun$NOME_MUNICIPIO)])

  [1] &amp;quot;BARRA DA CHOCA&amp;quot;                &amp;quot;DIAS D&amp;#39;VILA&amp;quot;                  
  [3] &amp;quot;LIVRAMENTO DO BRUMADO&amp;quot;         &amp;quot;MUQUEM DE SAO FRANCISCO&amp;quot;      
  [5] &amp;quot;OLIVERIA DOS BREJINHOS&amp;quot;        &amp;quot;PAU BRAZIL&amp;quot;                   
  [7] &amp;quot;QUIJINGUE&amp;quot;                     &amp;quot;ITAPAJE&amp;quot;                      
  [9] &amp;quot;MISSO VELHA&amp;quot;                   &amp;quot;SAO JOAO DO BELM&amp;quot;             
 [11] &amp;quot;SAO LUIZ DO CURU&amp;quot;              &amp;quot;GUIA BRANCA&amp;quot;                  
 [13] &amp;quot;ILHA TRINDADE&amp;quot;                 &amp;quot;ILHAS DE MARTIM VAZ&amp;quot;          
 [15] &amp;quot;AMERICANO DO BRAZIL&amp;quot;           &amp;quot;BRASABRANTES&amp;quot;                 
 [17] &amp;quot;MATEIRA&amp;quot;                       &amp;quot;PORTEIRO&amp;quot;                     
 [19] &amp;quot;SANTA RITA DE ARAGUAIA&amp;quot;        &amp;quot;ALTO ALEGRE DO MARANHO&amp;quot;       
 [21] &amp;quot;AMAPA DO MARANHO&amp;quot;              &amp;quot;ANAPUROS&amp;quot;                     
 [23] &amp;quot;BOM JARDIN&amp;quot;                    &amp;quot;HUMBERTO CAMPOS&amp;quot;              
 [25] &amp;quot;MATES DO NORTE&amp;quot;                &amp;quot;VICTORINO FREIRE&amp;quot;             
 [27] &amp;quot;BATAIPORA&amp;quot;                     &amp;quot;BARRA DOS BUGRE&amp;quot;              
 [29] &amp;quot;POXOREO&amp;quot;                       &amp;quot;SAO FELIX XINGU&amp;quot;              
 [31] &amp;quot;BANDIERA DO SUL&amp;quot;               &amp;quot;BRASOPOLIS&amp;quot;                   
 [33] &amp;quot;CACHOEIRA DE PAJES&amp;quot;            &amp;quot;CAMPOS VERDES DE GOIAS&amp;quot;       
 [35] &amp;quot;CARAVALHOPOLIS&amp;quot;                &amp;quot;CASSITERITA&amp;quot;                  
 [37] &amp;quot;CHAVESLANDIA&amp;quot;                  &amp;quot;FELISBERTO CALDEIRA&amp;quot;          
 [39] &amp;quot;FRANCISCO DUMON&amp;quot;               &amp;quot;GOUVEA&amp;quot;                       
 [41] &amp;quot;ITABIRINHA DE MANTENA&amp;quot;         &amp;quot;ITACARAMBIRA&amp;quot;                 
 [43] &amp;quot;PIEDADE DO PONTE NOVA&amp;quot;         &amp;quot;PIUI&amp;quot;                         
 [45] &amp;quot;QUELUZITA&amp;quot;                     &amp;quot;SAO FRANCISCO DE OLIVEIRA&amp;quot;    
 [47] &amp;quot;SAO SEBASTIO DA VARGEM ALEGRE&amp;quot; &amp;quot;SAN ANTONIO DO ITAMBE&amp;quot;        
 [49] &amp;quot;SAN ANTONIO DO RIO ABAI&amp;quot;       &amp;quot;SANTA RITA DO IBITIPOCA&amp;quot;      
 [51] &amp;quot;SANTA RITA ITUETO&amp;quot;             &amp;quot;ALMERIM&amp;quot;                      
 [53] &amp;quot;BRAGANGA&amp;quot;                      &amp;quot;ME DO RIO&amp;quot;                    
 [55] &amp;quot;BOQUEIRAO DOS COCHOS&amp;quot;          &amp;quot;DESTERRO DE MALTA&amp;quot;            
 [57] &amp;quot;MONGEIRO&amp;quot;                      &amp;quot;PEDRA LAVADRA&amp;quot;                
 [59] &amp;quot;RIACHO&amp;quot;                        &amp;quot;SAO MIGUEL TAIPU&amp;quot;             
 [61] &amp;quot;SERIDO&amp;quot;                        &amp;quot;ALTAMIRA DO PARAN&amp;quot;            
 [63] &amp;quot;ARAPU&amp;quot;                         &amp;quot;ASSIS CHATEAUBRI&amp;quot;             
 [65] &amp;quot;CAMPO&amp;quot;                         &amp;quot;CONSELHEIRO MAYRINCK&amp;quot;         
 [67] &amp;quot;IVATUVA&amp;quot;                       &amp;quot;JABUTI&amp;quot;                       
 [69] &amp;quot;SAO ANTONIO DE SUDOESTE&amp;quot;       &amp;quot;SALTO DO LONDRA&amp;quot;              
 [71] &amp;quot;SANTA CRUZ DE MONTE CASTE&amp;quot;     &amp;quot;SANTA ISABEL DO OESTE&amp;quot;        
 [73] &amp;quot;TEXEIRA SOARES&amp;quot;                &amp;quot;TIBAJI&amp;quot;                       
 [75] &amp;quot;VENCESLAU BRAS&amp;quot;                &amp;quot;VILA ALTA&amp;quot;                    
 [77] &amp;quot;BARRA DE GUABIRA&amp;quot;              &amp;quot;CABO&amp;quot;                         
 [79] &amp;quot;CACHOERINHA&amp;quot;                   &amp;quot;IGARACU&amp;quot;                      
 [81] &amp;quot;LAGOA DO ITAENGA&amp;quot;              &amp;quot;SAO JOAO DO BELMONTE&amp;quot;         
 [83] &amp;quot;SAO JOAQUIN DO MONTE&amp;quot;          &amp;quot;SITIO DOS MOREIRAS&amp;quot;           
 [85] &amp;quot;TAMBE&amp;quot;                         &amp;quot;PEDRO LI&amp;quot;                     
 [87] &amp;quot;SAO JOAO PIAUI&amp;quot;                &amp;quot;SAO MIGUEL TAPUIO&amp;quot;            
 [89] &amp;quot;CAMPOS&amp;quot;                        &amp;quot;CAREPEBUS&amp;quot;                    
 [91] &amp;quot;CONCEICAO MACABU&amp;quot;              &amp;quot;ENGENHEIRO PAULO DE FRONT&amp;quot;    
 [93] &amp;quot;PARATI&amp;quot;                        &amp;quot;VALENCIA&amp;quot;                     
 [95] &amp;quot;ACU&amp;quot;                           &amp;quot;AUGUSTO SEVERO&amp;quot;               
 [97] &amp;quot;GOVERNADOR DIX-SEPT ROSAD&amp;quot;     &amp;quot;JANUARIO CICCO&amp;quot;               
 [99] &amp;quot;JARDIM-PIRANHAS&amp;quot;               &amp;quot;JUNCO&amp;quot;                        
[101] &amp;quot;LAGOA DE ANTA&amp;quot;                 &amp;quot;LAGOAS DE VELHOS&amp;quot;             
[103] &amp;quot;SAO MIGUEL DE TOUROS&amp;quot;          &amp;quot;BAJE&amp;quot;                         
[105] &amp;quot;BARO&amp;quot;                          &amp;quot;BOA VISTA DAS MISSES&amp;quot;         
[107] &amp;quot;CAMAGUA&amp;quot;                       &amp;quot;CAMPO REAL&amp;quot;                   
[109] &amp;quot;CHIAPETA&amp;quot;                      &amp;quot;DILERMANO DE AGUIAR&amp;quot;          
[111] &amp;quot;ERVAL&amp;quot;                         &amp;quot;INHACOR&amp;quot;                      
[113] &amp;quot;LAGOA MIRIM&amp;quot;                   &amp;quot;MARCIONILIO DIAS&amp;quot;             
[115] &amp;quot;MAXIMILIANO DE ALMAEIDA&amp;quot;       &amp;quot;PALMITINHOS&amp;quot;                  
[117] &amp;quot;SAO MIGUEL DAS MISSES&amp;quot;         &amp;quot;UREA&amp;quot;                         
[119] &amp;quot;VITORIA DAS MISSES&amp;quot;            &amp;quot;ALTA FLORESTA D&amp;#39;OESTE&amp;quot;        
[121] &amp;quot;ALVORADA D&amp;#39;OESTE&amp;quot;              &amp;quot;ESPIGAO D&amp;#39;OESTE&amp;quot;              
[123] &amp;quot;NOVA BRASILANDIA D&amp;#39;OESTE&amp;quot;      &amp;quot;SAO FELIPE D&amp;#39;OESTE&amp;quot;           
[125] &amp;quot;SANTA LUZIA D&amp;#39;OESTE&amp;quot;           &amp;quot;ALFREDO MARCONDE&amp;quot;             
[127] &amp;quot;APARECIDA DOESTE&amp;quot;              &amp;quot;BRODOSQUI&amp;quot;                    
[129] &amp;quot;DULCINOPOLIS&amp;quot;                  &amp;quot;EMBU&amp;quot;                         
[131] &amp;quot;ESTRELA DO OESTE&amp;quot;              &amp;quot;FERNO&amp;quot;                        
[133] &amp;quot;FERRAZ DE VASCON&amp;quot;              &amp;quot;FLORINIA&amp;quot;                     
[135] &amp;quot;GUARANI DO OESTE&amp;quot;              &amp;quot;IPAUCU&amp;quot;                       
[137] &amp;quot;JABUTICABAL&amp;quot;                   &amp;quot;LUISIANIA&amp;quot;                    
[139] &amp;quot;PALMEIRA DO OESTE&amp;quot;             &amp;quot;PARANAPAREMA&amp;quot;                 
[141] &amp;quot;PIRACUNUNGA&amp;quot;                   &amp;quot;PONTES GESTRAL&amp;quot;               
[143] &amp;quot;QUITANA&amp;quot;                       &amp;quot;SAO LUIZ DO PARAITINGA&amp;quot;       
[145] &amp;quot;SALTO DO PIRAPORA&amp;quot;             &amp;quot;SANTA CLARA DO OESTE&amp;quot;         
[147] &amp;quot;SANTA RITA DO OESTE&amp;quot;           &amp;quot;GRAO PARA&amp;quot;                    
[149] &amp;quot;LUIZ ALVES&amp;quot;                    &amp;quot;PAULO LOPEZ&amp;quot;                  
[151] &amp;quot;PICARRAS&amp;quot;                      &amp;quot;PONTA ALTA&amp;quot;                   
[153] &amp;quot;BUQUIM&amp;quot;                        &amp;quot;GRACHO CARDOSO&amp;quot;               
[155] &amp;quot;ITAPORANGA DAJUDA&amp;quot;             &amp;quot;NOSSA SENHORA APRECIDO&amp;quot;       
[157] &amp;quot;COUTO MAGALHAES&amp;quot;               &amp;quot;MOSQUITO&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Hmmm, that’s a little annoying, but some are easy to fix, so in the end, we’ll be missing only a few municipalities because of these coding differences. Some others are harder to figure out: I don’t know if the errors are in the TSE’s data, or in this geo-data. I don’t feel like spending a long time recoding stuff though, so let’s leave it aside for now.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;BRmap@data$NAME_2[BRmap@data$NAME_2==&amp;quot;ASSIS BRAZIL&amp;quot;] &amp;lt;- &amp;quot;ASSIS BRASIL&amp;quot;
BRmap@data$NAME_2[BRmap@data$NAME_2==&amp;quot;JOINVILE&amp;quot;] &amp;lt;- &amp;quot;JOINVILLE&amp;quot;
BRmap@data$NAME_2[BRmap@data$NAME_2==&amp;quot;MACEIO (CAPITAL)&amp;quot;] &amp;lt;- &amp;quot;MACEIO&amp;quot;
BRmap@data$NAME_2[BRmap@data$NAME_2==&amp;quot;SAO GABRIEL DE CAHOEIRA&amp;quot;] &amp;lt;- &amp;quot;SAO GABRIEL DA CACHOEIRA&amp;quot;
BRmap@data$NAME_2[BRmap@data$NAME_2==&amp;quot;NOVO BRAZIL&amp;quot;] &amp;lt;- &amp;quot;NOVO BRASIL&amp;quot;
BRmap@data$NAME_2[BRmap@data$NAME_2==&amp;quot;PERI-MIRIM&amp;quot;] &amp;lt;- &amp;quot;PERI MIRIM&amp;quot;
BRmap@data$NAME_2[BRmap@data$NAME_2==&amp;quot;SEM-PEIXE&amp;quot;] &amp;lt;- &amp;quot;SEM PEIXE&amp;quot;
BRmap@data$NAME_2[BRmap@data$NAME_2==&amp;quot;BRAZIL NOVO&amp;quot;] &amp;lt;- &amp;quot;BRASIL NOVO&amp;quot;
BRmap@data$NAME_2[BRmap@data$NAME_2==&amp;quot;OLHOS-D&amp;#39;AGUA&amp;quot;] &amp;lt;- &amp;quot;OLHOS D&amp;#39;AGUA&amp;quot;
BRmap@data$NAME_2[BRmap@data$NAME_2==&amp;quot;OLHO-D&amp;#39;AGUA DO BORGES&amp;quot;] &amp;lt;- &amp;quot;OLHO D&amp;#39;AGUA DO BORGES&amp;quot;
BRmap@data$NAME_2[BRmap@data$NAME_2==&amp;quot;SERRA DA SAUDAD&amp;quot;] &amp;lt;- &amp;quot;SERRA DA SAUDADE&amp;quot;
BRmap@data$NAME_2[BRmap@data$NAME_2==&amp;quot;PEIXE BOI&amp;quot;] &amp;lt;- &amp;quot;PEIXE-BOI&amp;quot;
BRmap@data$NAME_2[BRmap@data$NAME_2==&amp;quot;RICAHO DOS CAVALOS&amp;quot;] &amp;lt;- &amp;quot;RIACHO DOS CAVALOS&amp;quot;
BRmap@data$NAME_2[BRmap@data$NAME_2==&amp;quot;BRAZILEIRA&amp;quot;] &amp;lt;- &amp;quot;BRASILEIRA&amp;quot;
BRmap@data$NAME_2[BRmap@data$NAME_2==&amp;quot;SUL BRAZIL&amp;quot;] &amp;lt;- &amp;quot;SUL BRASIL&amp;quot;
BRmap@data$NAME_2[BRmap@data$NAME_2==&amp;quot;FLORINIAPOLIS&amp;quot;] &amp;lt;- &amp;quot;FLORIANOPOLIS&amp;quot;
BRmap@data$NAME_2[BRmap@data$NAME_2==&amp;quot;BON JESUS DOS PERDOES&amp;quot;] &amp;lt;- &amp;quot;BOM JESUS DOS PERDOES&amp;quot;
BRmap@data$NAME_2[BRmap@data$NAME_2==&amp;quot;OLHO-D&amp;#39;AGUA DO BORGES&amp;quot;] &amp;lt;- &amp;quot;OLHO D&amp;#39;AGUA DO BORGES&amp;quot;
BRmap@data$NAME_2[BRmap@data$NAME_2==&amp;quot;MISSO&amp;quot;] &amp;lt;- &amp;quot;MISSAO&amp;quot;
BRmap@data$NAME_2[BRmap@data$NAME_2==&amp;quot;SALIDAO&amp;quot;] &amp;lt;- &amp;quot;SOLIDAO&amp;quot;
BRmap@data$NAME_2[BRmap@data$NAME_2==&amp;quot;SAO JOAO DAS DUAS PONTE&amp;quot;] &amp;lt;- &amp;quot;SAO JOAO DAS DUAS PONTES&amp;quot;
BRmap@data$NAME_2[BRmap@data$NAME_2==&amp;quot;ORLEAES&amp;quot;] &amp;lt;- &amp;quot;ORLEANS&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can use &lt;code&gt;fortify&lt;/code&gt; to get all this into something useful for &lt;code&gt;ggplot()&lt;/code&gt; to deal with. Then we can add in all the data we have for Dilma’s vote totals and then we’re ready to plot something.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Brasil &amp;lt;- fortify(BRmap, region = &amp;quot;ID_2&amp;quot;) %&amp;gt;%  
  mutate(id = as.integer(id)) %&amp;gt;%
  full_join(BRmap@data, by =c(&amp;quot;id&amp;quot; = &amp;quot;ID_2&amp;quot;)) %&amp;gt;%
  select(c(id, long, lat, order, hole, piece, group, NAME_2)) %&amp;gt;%
  rename(NOME_MUNICIPIO = NAME_2)

head(Brasil)
  id      long       lat order  hole piece group NOME_MUNICIPIO
1  1 -67.10586 -9.688110     1 FALSE     1   1.1     ACRELANDIA
2  1 -67.05984 -9.706651     2 FALSE     1   1.1     ACRELANDIA
3  1 -66.80647 -9.814520     3 FALSE     1   1.1     ACRELANDIA
4  1 -66.62003 -9.894039     4 FALSE     1   1.1     ACRELANDIA
5  1 -66.58875 -9.903196     5 FALSE     1   1.1     ACRELANDIA
6  1 -66.62333 -9.923209     6 FALSE     1   1.1     ACRELANDIA


Dilma_1 &amp;lt;- left_join(Brasil, Pres1) %&amp;gt;%
  mutate(PERC = ifelse(is.na(PERC), mean(PERC, na.rm=T), PERC))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot() +
  geom_polygon(data = Dilma_1, aes(x = long, y = lat,
                                   group = group, fill = PERC),
               color = &amp;quot;white&amp;quot;, size = 0.1) +
  scale_fill_distiller(palette = &amp;quot;RdBu&amp;quot;,
                       breaks = pretty_breaks(n = 8)) +
  guides(fill = guide_legend(reverse = TRUE)) +
  labs(fill = &amp;quot;Dilma (%)&amp;quot;) +
  theme_nothing(legend = TRUE) +
  xlim(range(Dilma_1$long)) + ylim(range(Dilma_1$lat)) +
  coord_map()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://i.imgur.com/xYMEQrk.jpg&#34; style=&#34;width:800px;height:800px;&#34;&gt;&lt;/p&gt;
&lt;p&gt;We can see that even in 2014, Dilma’s support in the South-east of the country was not overwhelming.&lt;/p&gt;
&lt;p&gt;We can also use &lt;code&gt;electionsBR&lt;/code&gt; to look at other items of interest, such as the share of the party vote. For example, perhaps you’re interested in whether the Communist Party of Brazil has strongholds in the country. All we need to do is subset the &lt;code&gt;Mun&lt;/code&gt; dataframe that we downloaded earlier by &lt;code&gt;DESCRICAO_CARGO == &amp;quot;DEPUTADO FEDERAL&amp;quot;&lt;/code&gt; and &lt;code&gt;SIGLA_PARTIDO == &amp;quot;PC do B&amp;quot;&lt;/code&gt;. Apart from these changes, everything else can be done in the same way. Once we have this dataframe (which I’ll call &lt;code&gt;pc&lt;/code&gt;), we plot it in the same way:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot() +
  geom_polygon(data = pc, aes(x = long, y = lat, group = group,
                              fill = PERC),
               color = &amp;quot;white&amp;quot;, size = 0.1) +
  scale_fill_distiller(palette = &amp;quot;RdBu&amp;quot;,
                       breaks = pretty_breaks(n = 8)) +
  guides(fill = guide_legend(reverse = TRUE)) +
  labs(fill = &amp;quot;PC do B (%)&amp;quot;) +
  theme_nothing(legend = TRUE) +
  xlim(range(pc$long)) + ylim(range(pc$lat)) +
  coord_map()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://i.imgur.com/jXKjZgG.jpg&#34; style=&#34;width:800px;height:800px;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Not a very Communist country, by the looks of things.&lt;/p&gt;
&lt;p&gt;Well, that’s a brief look at &lt;code&gt;electionsBR&lt;/code&gt;. Data for other years and elections is available, as well as data at other administrative levels, and not just the President and Federal Deputies. The TSE also holds data on the background of the candidates and their campaign spending, all of which can be utilized with &lt;code&gt;electionsBR&lt;/code&gt;. And if you fancy combining all this information with legislative behaviour from inside the Chamber of Deputies, just load the &lt;code&gt;bRasilLegis&lt;/code&gt; package and you have a wealth of data on Brazilian Federal Deputies at your fingertips. Indeed, I’m proud to be involved in both packages. It’s great to help to make the access to these data easier for those interested in Brazilian politics.&lt;/p&gt;
&lt;p&gt;P.s. This blog post was written using &lt;a href=&#34;http://rmarkdown.rstudio.com/r_notebooks.html&#34;&gt;&lt;code&gt;R Notebooks&lt;/code&gt;&lt;/a&gt;. I’d have to say that I really like &lt;code&gt;R Notebooks&lt;/code&gt; so far, especially the preview. Try it out.&lt;/p&gt;
&lt;p&gt;Update: it seems that some folks might be running into problems running the scripts above, with &lt;strong&gt;R&lt;/strong&gt; spitting out: &lt;code&gt;Error: isTRUE(gpclibPermitStatus()) is not TRUE&lt;/code&gt;. The solution to this is to make sure you have rgdal or rgeos or a similar mapping package installed.&lt;/p&gt;
&lt;p&gt;&lt;b id=&#34;fn1&#34;&gt;1&lt;/b&gt; Disclosure: I’m (very lightly) involved in the development of this package, but I am not one of the original developers, that credit goes to &lt;a href=&#34;https://github.com/silvadenisson/electionsBR&#34;&gt;Denisson Silva&lt;/a&gt;, Fernando Meireles, and Beatriz Costa. Nevertheless, I’m promoting it here because I think it’s great, not because I’m involved. (Although I’m involved because I think it’s great :smile: ) &lt;a href=&#34;#a1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;


&lt;!-- BLOGDOWN-HEAD




/BLOGDOWN-HEAD --&gt;
</description>
    </item>
    
    <item>
      <title>Re-creating Plots from The Economist in R and ggplot2</title>
      <link>/re-creating-plots-from-the-economist-in-r.html</link>
      <pubDate>Sun, 21 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>/re-creating-plots-from-the-economist-in-r.html</guid>
      <description>&lt;!-- BLOGDOWN-BODY-BEFORE

/BLOGDOWN-BODY-BEFORE --&gt;

&lt;p&gt;&lt;img src=&#34;http://i.imgur.com/1xvEaYe.png?3&#34; align=&#34;middle&#34; style=&#34;width:200px; height:350px;&#34;&gt;&lt;/p&gt;
&lt;p&gt;The Economist is well known for its graphs and images, and I personally like them a lot. I was doing some work on Brexit when I spied the image above, and thought how much I would like to make something similar. Since my go-to environment is R, and its go-to plotting package &lt;code&gt;ggplot2&lt;/code&gt;, I thought I’d try to recreate the image using these tools. (Hat tip: I was half-way through doing this, and getting a little irritated with British place names, when I came across this fantastic &lt;a href=&#34;http://rpubs.com/rouille/191996&#34;&gt;RPub&lt;/a&gt;, which helped a lot with the area names. The code below that deals with cleaning up and merging the administrative area data comes from Benjamin. Thanks, chief!)&lt;/p&gt;
&lt;p&gt;The data that we start off with is available from the UK &lt;a href=&#34;http://www.electoralcommission.org.uk/find-information-by-subject/elections-and-referendums/past-elections-and-referendums/eu-referendum&#34;&gt;Electoral Commission&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rgdal)
library(maptools)
library(dplyr)
library(ggplot2)
library(readr)
library(httr)
library(ggmap)
library(scales)


brex &amp;lt;- read_csv(&amp;quot;https://raw.githubusercontent.com/RobertMyles/RobertMyles.github.io/master/_data/EU-referendum-result-data.csv&amp;quot;)

# Fix up place names:

uk.map &amp;lt;- readOGR(dsn = &amp;quot;GBR_adm_shp&amp;quot;, layer = &amp;quot;GBR_adm2&amp;quot;, verbose = FALSE)
uk.map@data$NAME_2 &amp;lt;- as.character(uk.map@data$NAME_2)
uk.map@data$NAME_2[56]  &amp;lt;- &amp;quot;City of London&amp;quot;
uk.map@data$NAME_2[140] &amp;lt;- &amp;quot;Aberdeen City&amp;quot;
uk.map@data$NAME_2[145] &amp;lt;- &amp;quot;Dundee City&amp;quot;
uk.map@data$NAME_2[150] &amp;lt;- &amp;quot;City of Edinburgh&amp;quot;
uk.map@data$NAME_2[154] &amp;lt;- &amp;quot;Glasgow City&amp;quot;
uk.map@data$NAME_2[159] &amp;lt;- &amp;quot;North Ayrshire&amp;quot;
uk.map@data$NAME_2[162] &amp;lt;- &amp;quot;Perth and Kinross&amp;quot;
uk.map@data$NAME_2[171] &amp;lt;- &amp;quot;Isle of Anglesey&amp;quot;
uk.map@data$NAME_2[188] &amp;lt;- &amp;quot;Rhondda Cynon Taf&amp;quot;

url &amp;lt;- &amp;quot;https://en.wikipedia.org/wiki/List_of_English_districts&amp;quot;
tables &amp;lt;- GET(url)
tables &amp;lt;- readHTMLTable(rawToChar(tables$content))
n.rows &amp;lt;- unlist(lapply(tables, function(t) dim(t)[1]))

districts &amp;lt;- tables[[which.max(n.rows)]]
names(districts) &amp;lt;- c(&amp;quot;Name&amp;quot;, &amp;quot;Website&amp;quot;, &amp;quot;Population2015&amp;quot;, &amp;quot;Type&amp;quot;,
&amp;quot;CeremonialCounty&amp;quot;)
districts$Name &amp;lt;- gsub(&amp;quot;&amp;amp;&amp;quot;, &amp;quot;and&amp;quot;, districts$Name)
districts$Name[133] &amp;lt;- &amp;quot;Kingston upon Hull&amp;quot;
districts$id     &amp;lt;- NA
districts$Leave  &amp;lt;- 0
districts$Remain &amp;lt;- 0
districts$Valid  &amp;lt;- 0


wEngland &amp;lt;- which(uk.map@data$NAME_1 == &amp;quot;England&amp;quot;)
for(i in wEngland ) {
  if(uk.map$TYPE_2[i] == &amp;quot;Administrative County&amp;quot; | uk.map$TYPE_2[i] == &amp;quot;Metropolitan County&amp;quot; |
     uk.map$TYPE_2[i] == &amp;quot;County&amp;quot; | uk.map$TYPE_2[i] == &amp;quot;Metropolitan Borough (city)&amp;quot;) {
    match &amp;lt;- grep(uk.map$NAME_2[i], districts$CeremonialCounty)
    for(j in match) if(is.na(districts$id[j]) ) districts$id[j] &amp;lt;- uk.map$ID_2[i]
  } else {
    match &amp;lt;- match(uk.map$NAME_2[i], districts$Name)
    districts$id[match] &amp;lt;- uk.map$ID_2[i]
  }
}

for(i in 1:nrow(districts) ) {
  match &amp;lt;- match(districts$Name[i], brex$Area)
  if(is.na(match) ) match &amp;lt;- grep(districts$Name[i], brex$Area)
  districts$Leave[i]  &amp;lt;- brex$Leave[match]
  districts$Remain[i] &amp;lt;- brex$Remain[match]
  districts$Valid[i]  &amp;lt;- brex$Valid_Votes[match]
}

england &amp;lt;- with(districts, data.frame(Name   = uk.map@data$NAME_2[wEngland],
           Leave  = tapply(Leave, id, sum, na.rm = TRUE),
           Remain = tapply(Remain, id, sum, na.rm = TRUE),
           Valid  = tapply(Valid, id, sum, na.rm = TRUE),
           Country = &amp;quot;England&amp;quot;,
           id     = uk.map@data$ID_2[wEngland]))

wIreland &amp;lt;- which(uk.map@data$NAME_1 == &amp;quot;Northern Ireland&amp;quot;)

ireland &amp;lt;- with(brex, data.frame(Name   = uk.map@data$NAME_2[wIreland],
                                 Country = &amp;quot;N. Ireland&amp;quot;,
                                 Leave  = rep(Leave[grep(&amp;quot;N&amp;quot;,Region_Code)], each = length(wIreland) ),
                                 Remain = rep(Remain[grep(&amp;quot;N&amp;quot;,Region_Code)], each = length(wIreland) ),
                                 Valid  = rep(Valid_Votes[grep(&amp;quot;N&amp;quot;,Region_Code)], each = length(wIreland) ),
                                 id     = uk.map@data$ID_2[wIreland]))

scotland &amp;lt;- with(brex, data.frame(Name   = Area[grep(&amp;quot;S&amp;quot;,Region_Code)], 
                                  Leave  = Leave[grep(&amp;quot;S&amp;quot;,Region_Code)], 
                                  Country = &amp;quot;Scotland&amp;quot;,
                                  Remain = Remain[grep(&amp;quot;S&amp;quot;,Region_Code)], 
                                  Valid  = Valid_Votes[grep(&amp;quot;S&amp;quot;,Region_Code)],
                                  id     = rep(NA,length(grep(&amp;quot;S&amp;quot;,Region_Code)) ) ) )

for(i in 1:nrow(scotland) ) {
  match &amp;lt;- match(scotland$Name[i],uk.map@data$NAME_2)
  scotland$id[i] &amp;lt;- uk.map@data$ID_2[match]
}
wales &amp;lt;- with(brex, data.frame(Name   = Area[grep(&amp;quot;W&amp;quot;,Region_Code)], 
                               Leave  = Leave[grep(&amp;quot;W&amp;quot;,Region_Code)], 
                               Country = &amp;quot;Wales&amp;quot;,
                               Remain = Remain[grep(&amp;quot;W&amp;quot;,Region_Code)], 
                               Valid  = Valid_Votes[grep(&amp;quot;W&amp;quot;,Region_Code)],
                               id     = length(grep(&amp;quot;W&amp;quot;,Region_Code) ) ) )

for(i in 1:nrow(wales) ) {
  match &amp;lt;- match(wales$Name[i],uk.map@data$NAME_2)
  wales$id[i] &amp;lt;- uk.map@data$ID_2[match]
}

cities.name2 &amp;lt;- c(&amp;quot;Blackburn, UK&amp;quot;, &amp;quot;Port Talbot, UK&amp;quot;, &amp;quot;Northampton, UK&amp;quot;, &amp;quot;London, UK&amp;quot;)
cities.coordinates &amp;lt;- geocode(cities.name2, messaging = FALSE)
cities.lon &amp;lt;- cities.coordinates$lon
cities.lat &amp;lt;- cities.coordinates$lat


uk &amp;lt;- rbind(england, ireland, scotland, wales)
uk$pct_Leave  &amp;lt;- 100*uk$Leave/uk$Valid
uk$pct_Remain &amp;lt;- 100*uk$Remain/uk$Valid

uk.points &amp;lt;- fortify(uk.map, region = &amp;quot;ID_2&amp;quot;)
uk$id &amp;lt;- as.character(uk$id)
uk.plot &amp;lt;- left_join(uk.points,uk)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;All of this has given us &lt;em&gt;almost&lt;/em&gt; what we need. The areas in the Economist’s image don’t quite match up with the administrative districts from the Electoral Commission data, in the sense that many are amalgamations of admistrative districts. Since we don’t have any variable in our dataset describing this mapping, we’ll have to do this manually.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;uk.plot$Import_shock &amp;lt;- NA

One &amp;lt;- c(&amp;quot;Cumbria&amp;quot;, &amp;quot;Lancashire&amp;quot;, &amp;quot;Northamptonshire&amp;quot;, &amp;quot;Leicestershire&amp;quot;, &amp;quot;Leicester&amp;quot;, &amp;quot;Blackburn with Darwen&amp;quot;, &amp;quot;Manchester&amp;quot;, &amp;quot;Rutland&amp;quot;)
Two &amp;lt;- c(&amp;quot;Telford and Wrekin&amp;quot;, &amp;quot;Derbyshire&amp;quot;, &amp;quot;West Midlands&amp;quot;, &amp;quot;Stoke-on-Trent&amp;quot;, &amp;quot;Shropshire&amp;quot;, &amp;quot;Staffordshire&amp;quot;, &amp;quot;Nottinghamshire&amp;quot;, &amp;quot;Derby&amp;quot;, &amp;quot;Nottingham&amp;quot;, &amp;quot;West Yorkshire&amp;quot;)
Three &amp;lt;- c(&amp;quot;Herefordshire&amp;quot;, &amp;quot;Worcestershire&amp;quot;, &amp;quot;Essex&amp;quot;, &amp;quot;Warwickshire&amp;quot;, &amp;quot;Southend-on-Sea&amp;quot;, &amp;quot;Thurrock&amp;quot;, &amp;quot;Havering&amp;quot;)
Four &amp;lt;- c(&amp;quot;Bridgend&amp;quot;, &amp;quot;Isle of Anglesey&amp;quot;, &amp;quot;Gwynedd&amp;quot;, &amp;quot;Ceredigion&amp;quot;, &amp;quot;Carmarthenshire&amp;quot;, &amp;quot;Pembrokeshire&amp;quot;, &amp;quot;Swansea&amp;quot;, &amp;quot;Rhondda Cynon Taf&amp;quot;, &amp;quot;Neath Port Talbot&amp;quot;, &amp;quot;Caerphilly&amp;quot;, &amp;quot;Merthyr Tydfil&amp;quot;, &amp;quot;Torfaen&amp;quot;, &amp;quot;Somerset&amp;quot;, &amp;quot;Dorset&amp;quot;, &amp;quot;Isle of Wight&amp;quot;, &amp;quot;Hampshire&amp;quot;, &amp;quot;Conwy&amp;quot;, &amp;quot;Suffolk&amp;quot;, &amp;quot;Durham&amp;quot;, &amp;quot;Tyne and Wear&amp;quot;, &amp;quot;Denbighshire&amp;quot;, &amp;quot;Cambridgeshire&amp;quot;, &amp;quot;Luton&amp;quot;, &amp;quot;Hertfordshire&amp;quot;, &amp;quot;Bedfordshire&amp;quot;, &amp;quot;Berkshire&amp;quot;, &amp;quot;Poole&amp;quot;, &amp;quot;Southampton&amp;quot;, &amp;quot;Portsmouth&amp;quot;, &amp;quot;Redcar and Cleveland&amp;quot;, &amp;quot;Stockton-on-Tees&amp;quot;, &amp;quot;Darlington&amp;quot;, &amp;quot;Hartlepool&amp;quot;, &amp;quot;Bornemouth&amp;quot;, &amp;quot;Blaenau Gwent&amp;quot;)
Five &amp;lt;- c(&amp;quot;Northumberland&amp;quot;, &amp;quot;Norfolk&amp;quot;, &amp;quot;South Yorkshire&amp;quot;, &amp;quot;Enfield&amp;quot;, &amp;quot;Brent&amp;quot;)
Six &amp;lt;- c(&amp;quot;South Ayrshire&amp;quot;, &amp;quot;North Ayshire&amp;quot;, &amp;quot;Dumfries and Galloway&amp;quot;, &amp;quot;South Lanarkshire&amp;quot;, &amp;quot;North Lanarkshire&amp;quot;, &amp;quot;East Ayrshire&amp;quot;, &amp;quot;Renfrewshire&amp;quot;, &amp;quot;West Dunbartonshire&amp;quot;, &amp;quot;East Renfrewshire&amp;quot;, &amp;quot;Glasgow City&amp;quot;, &amp;quot;East Dunbartonshire&amp;quot;, &amp;quot;Inverclyde&amp;quot;, &amp;quot;Lincolnshire&amp;quot;, &amp;quot;West Sussex&amp;quot;, &amp;quot;East Sussex&amp;quot;, &amp;quot;Brighton and Hove&amp;quot;, &amp;quot;Surrey&amp;quot;, &amp;quot;Oxfordshire&amp;quot;, &amp;quot;Buckinghamshire&amp;quot;, &amp;quot;Milton Keynes&amp;quot;, &amp;quot;Peterborough&amp;quot;, &amp;quot;Sutton&amp;quot;, &amp;quot;Croydon&amp;quot;)
Seven &amp;lt;- c(&amp;quot;Angus&amp;quot;, &amp;quot;Dundee City&amp;quot;, &amp;quot;Scottish Borders&amp;quot;, &amp;quot;East Lothian&amp;quot;, &amp;quot;Midlothian&amp;quot;, &amp;quot;Fife&amp;quot;, &amp;quot;Perth and Kinross&amp;quot;, &amp;quot;City of Edinburgh&amp;quot;, &amp;quot;Stirling&amp;quot;, &amp;quot;Falkirk&amp;quot;, &amp;quot;West Lothian&amp;quot;, &amp;quot;Clackmannanshire&amp;quot;, &amp;quot;Powys&amp;quot;, &amp;quot;Cheshire&amp;quot;, &amp;quot;Vale of Glamorgan&amp;quot;, &amp;quot;Newport&amp;quot;, &amp;quot;Cardiff&amp;quot;, &amp;quot;Warrington&amp;quot;, &amp;quot;Halton&amp;quot;, &amp;quot;Flintshire&amp;quot;, &amp;quot;Wrexham&amp;quot;, &amp;quot;Monmouthshire&amp;quot;, &amp;quot;Bromley&amp;quot;, &amp;quot;Hillingdon&amp;quot;, &amp;quot;Harrow&amp;quot;)
Eight &amp;lt;- c(&amp;quot;Devon&amp;quot;, &amp;quot;East Riding of Yorkshire&amp;quot;, &amp;quot;Kent&amp;quot;, &amp;quot;Merseyside&amp;quot;, &amp;quot;North East Lincolnshire&amp;quot;, &amp;quot;Swindon&amp;quot;, &amp;quot;Wiltshire&amp;quot;, &amp;quot;Gloucestershire&amp;quot;, &amp;quot;South Gloucestershire&amp;quot;, &amp;quot;North Somerset&amp;quot;, &amp;quot;Torbay&amp;quot;, &amp;quot;Bath and North East Somerset&amp;quot;, &amp;quot;Bristol&amp;quot;, &amp;quot;Kingston upon Hull&amp;quot;, &amp;quot;North Lincolnshire&amp;quot;, &amp;quot;Medway&amp;quot;)
Nine &amp;lt;- c(&amp;quot;Highlands&amp;quot;, &amp;quot;Argyll and Bute&amp;quot;, &amp;quot;North Yorkshire&amp;quot;, &amp;quot;Cornwall&amp;quot;, &amp;quot;Eilean Siar&amp;quot;)


uk.plot1 &amp;lt;- uk.plot %&amp;gt;% 
  filter(Name != &amp;quot;Shetland Islands&amp;quot;) %&amp;gt;% 
  filter(Country != &amp;quot;N. Ireland&amp;quot;) %&amp;gt;% 
  mutate(Import_shock = if_else(Name %in% One, 1, if_else(Name %in% Two, 2, if_else(Name %in% Three, 3, if_else(Name %in% Four, 4, if_else(Name %in% Five, 5, if_else(Name %in% Six, 6, if_else(Name %in% Seven, 7, if_else(Name %in% Eight, 8, if_else(Name %in% Nine, 9, 9)))))))))) %&amp;gt;% 
  filter(long &amp;gt; -10)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;So, after all that data tidying, we’re ready to make our plot. Since the Economist uses the ITC Officina Sans font, you’ll need that on your computer (or something similar). With the &lt;code&gt;extrafont&lt;/code&gt; package, we can take avail of these, well, extra fonts.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(extrafont)
font_import()
# There are various folders on my mac with fonts in them:
font_import(&amp;quot;/Users/robert/Library/Fonts/&amp;quot;)
font_import(&amp;quot;/System/Library/Fonts/&amp;quot;)
font_import(&amp;quot;/Library/Fonts/&amp;quot;)
loadfonts()
# see what&amp;#39;s available:
fonts()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;The following code makes the plot that I wanted, with the image saved and the font that I need embedded in the pdf that is produced. In Rstudio, no text will appear, as this font is not supported. But it’ll be in the pdf.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;MM &amp;lt;- ggplot() + 
  geom_polygon(data = uk.plot1, aes(x = long, y = lat, group = group, fill = Import_shock), colour = &amp;quot;white&amp;quot;, size = 0.1) +
  scale_fill_distiller(palette = &amp;quot;Reds&amp;quot;, breaks = pretty_breaks(n = 8)) +
  geom_point(aes(x = cities.lon, y = cities.lat), color = &amp;quot;black&amp;quot;, size = 2.5, shape = 21, fill = &amp;quot;black&amp;quot;) +
  geom_point(aes(x = cities.lon, y = cities.lat), color = &amp;quot;white&amp;quot;, size = 1, shape = 21, fill = &amp;quot;white&amp;quot;) +
  theme_nothing(legend = T) + 
  annotate(&amp;quot;text&amp;quot;, x=-4.75, y=52.5, label=&amp;quot;WALES&amp;quot;, size=4, family = &amp;quot;ITCOfficinaSans LT Book&amp;quot;) +
  annotate(&amp;quot;text&amp;quot;, x=1.12, y=53.65, label=&amp;quot;ENGLAND&amp;quot;, size=4, family = &amp;quot;ITCOfficinaSans LT Book&amp;quot;) +
  annotate(&amp;quot;text&amp;quot;, x=-2.2, y=57.9, label=&amp;quot;SCOTLAND&amp;quot;, size=4, family = &amp;quot;ITCOfficinaSans LT Book&amp;quot;) +
  annotate(&amp;quot;text&amp;quot;, x=-4.7, y=51.42, label=&amp;quot;Port Talbot&amp;quot;, size=3.45, family = &amp;quot;ITCOfficinaSans LT Book&amp;quot;) +
  annotate(&amp;quot;text&amp;quot;, x=.3, y=52.15, label=&amp;quot;Northampton&amp;quot;, size=3.45, family = &amp;quot;ITCOfficinaSans LT Book&amp;quot;) +
  annotate(&amp;quot;segment&amp;quot;, x = -3.3, xend = -2.5, y = 54, yend = 54) +
  annotate(&amp;quot;segment&amp;quot;, x = -2.5, xend = -2.5, y = 54, yend = 53.85) +
  annotate(&amp;quot;text&amp;quot;, x=-4.22, y=54, label=&amp;quot;Blackburn&amp;quot;, size=3.45, family = &amp;quot;ITCOfficinaSans LT Book&amp;quot;) +
  xlim(range(uk.plot1$long)) + ylim(range(uk.plot1$lat)) +
  theme(plot.background = element_rect(fill = &amp;quot;#A4D3EE&amp;quot;, colour = &amp;quot;#A4D3EE&amp;quot;), panel.background = element_rect(fill = &amp;quot;#A4D3EE&amp;quot;, colour = &amp;quot;#A4D3EE&amp;quot;), legend.position = &amp;quot;none&amp;quot;) +
  coord_map()
  

ggsave(&amp;quot;Brexit_test.pdf&amp;quot;, MM)
embed_fonts(&amp;quot;Brexit_test.pdf&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;  &lt;img src=&#34;http://i.imgur.com/P43D0jh.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;It’s not &lt;em&gt;exactly&lt;/em&gt; the same (I could &lt;em&gt;not&lt;/em&gt; get that legend to work right!), but I think it’s a pretty close match. Good, stuff, R :clap: .&lt;/p&gt;
&lt;p&gt;P.s. I know there are themes available to get close to the Economist’s image style, but I wanted do it myself :smiley:. Anyway, if you’d like to include the &lt;code&gt;theme_economist()&lt;/code&gt; function from the &lt;code&gt;ggthemes&lt;/code&gt; package, it’s easy:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Eco &amp;lt;- ggplot() + 
  geom_polygon(data = uk.plot1, aes(x = long, y = lat, group = group, fill = Import_shock), colour = &amp;quot;white&amp;quot;, size = 0.1) +
  scale_fill_distiller(palette = &amp;quot;Reds&amp;quot;, breaks = pretty_breaks(n = 8)) +
  geom_point(aes(x = cities.lon, y = cities.lat), color = &amp;quot;black&amp;quot;, size = 2.5, shape = 21, fill = &amp;quot;black&amp;quot;) +
  geom_point(aes(x = cities.lon, y = cities.lat), color = &amp;quot;white&amp;quot;, size = 1, shape = 21, fill = &amp;quot;white&amp;quot;) +
  theme_economist() +
  annotate(&amp;quot;text&amp;quot;, x=-4.75, y=52.5, label=&amp;quot;WALES&amp;quot;, size=4, family = &amp;quot;ITCOfficinaSans LT Book&amp;quot;) +
  annotate(&amp;quot;text&amp;quot;, x=1.12, y=53.65, label=&amp;quot;ENGLAND&amp;quot;, size=4, family = &amp;quot;ITCOfficinaSans LT Book&amp;quot;) +
  annotate(&amp;quot;text&amp;quot;, x=-2.2, y=57.9, label=&amp;quot;SCOTLAND&amp;quot;, size=4, family = &amp;quot;ITCOfficinaSans LT Book&amp;quot;) +
  annotate(&amp;quot;text&amp;quot;, x=-4.7, y=51.42, label=&amp;quot;Port Talbot&amp;quot;, size=3.45, family = &amp;quot;ITCOfficinaSans LT Book&amp;quot;) +
  annotate(&amp;quot;text&amp;quot;, x=.3, y=52.15, label=&amp;quot;Northampton&amp;quot;, size=3.45, family = &amp;quot;ITCOfficinaSans LT Book&amp;quot;) +
  annotate(&amp;quot;segment&amp;quot;, x = -3.3, xend = -2.5, y = 54, yend = 54) +
  annotate(&amp;quot;segment&amp;quot;, x = -2.5, xend = -2.5, y = 54, yend = 53.85) +
  annotate(&amp;quot;text&amp;quot;, x=-4.22, y=54, label=&amp;quot;Blackburn&amp;quot;, size=3.45, family = &amp;quot;ITCOfficinaSans LT Book&amp;quot;) +
  xlim(range(uk.plot1$long)) + ylim(range(uk.plot1$lat)) +
  theme(axis.ticks = element_blank(), axis.title = element_blank(), axis.text = element_blank(), panel.grid.major.y = element_blank(), legend.position = &amp;quot;none&amp;quot;) + 
  coord_map()

ggsave(&amp;quot;Brexit_test_Econ.pdf&amp;quot;, Eco)
embed_fonts(&amp;quot;Brexit_test_Econ.pdf&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The combination is better, actually:&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;http://i.imgur.com/t5322ak.png&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;If we put them side by side, you can see that we didn’t actually do a bad job.&lt;/p&gt;
&lt;blockquote class=&#34;imgur-embed-pub&#34; lang=&#34;en&#34; data-id=&#34;a/ivQ5t&#34;&gt;
&lt;a href=&#34;//imgur.com/ivQ5t&#34;&gt;&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;//s.imgur.com/min/embed.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;p&gt;Update: there are (of course) also &lt;a href=&#34;http://rpsychologist.com/creating-a-typical-textbook-illustration-of-statistical-power-using-either-ggplot-or-base-graphics?utm_content=buffer9beb5&amp;amp;utm_medium=social&amp;amp;utm_source=twitter.com&amp;amp;utm_campaign=buffer&#34;&gt;other great examples&lt;/a&gt; of using ggplot2 to recreate images, in this case textbook statistical distributions&lt;/p&gt;


&lt;!-- BLOGDOWN-HEAD




/BLOGDOWN-HEAD --&gt;
</description>
    </item>
    
    <item>
      <title>Geo-reference an image in R</title>
      <link>/geo-reference-an-image-in-r.html</link>
      <pubDate>Sat, 13 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>/geo-reference-an-image-in-r.html</guid>
      <description>&lt;!-- BLOGDOWN-BODY-BEFORE

/BLOGDOWN-BODY-BEFORE --&gt;

&lt;p&gt;R is actually great for working with spatial data (for example, see &lt;a href=&#34;http://spatial.ly/2012/03/mapped-british-shipping-1750-1800/&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://pakillo.github.io/R-GIS-tutorial/#gmap&#34;&gt;here&lt;/a&gt; for fantastic graphs and maps made with R), however, you often need data that is &lt;em&gt;actually spatial&lt;/em&gt; to get started! What do you do if you have an image, a map, let’s say, that is not geo-referenced in any way?&lt;br /&gt;
The regular answer to this problem is to use software such as &lt;a href=&#34;http://www.qgis.com/&#34;&gt;QGIS&lt;/a&gt; to manually enter GPS coordinates, with the &lt;a href=&#34;http://www.gps-coordinates.net/&#34;&gt;help&lt;/a&gt; of Google Maps or something similar. But R can be used for this too, and it’s quite easy to do.&lt;/p&gt;
&lt;p&gt;First, we load some necessary packages. Here, I’m working with &lt;code&gt;.tiff&lt;/code&gt; files that I will change into Geo-tiffs. For other formats, you will need some other packages (such as &lt;code&gt;png&lt;/code&gt;, for example).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(raster)
library(rgdal)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we read in the non-spatial image using the &lt;code&gt;raster&lt;/code&gt; command. By plotting this in RStudio, the image can be cropped in the preview window, if you want to crop it down the area of interest. This is also useful if the image came with extra, non-map parts (logos etc.).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Map &amp;lt;- raster(&amp;quot;1.tiff&amp;quot;)  
Map
plot(Map)
map2 &amp;lt;- crop(Map, drawExtent(show = TRUE, col = &amp;quot;red&amp;quot;)) 
plot(map2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can enter in the maximal points of the image, xmin/xmax and ymin/ymax, respectively. These coordinates refer to an area of São Paulo, Brazil. The x-axis is longitude, the y-axis latitude. You can get the coordinates from &lt;a href=&#34;http://www.gps-coordinates.net/&#34;&gt;www.gps-coordinates.net&lt;/a&gt; for the area you need. We also need to tell R what type of map projection we are going to write into the image. Here we’ll use &lt;code&gt;&amp;quot;+proj=longlat +datum=WGS84&amp;quot;&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;xmin(map2) &amp;lt;- -46.67449772357941 
xmax(map2) &amp;lt;- -46.524503231048584 
ymin(map2) &amp;lt;- -23.638627166908787
ymax(map2) &amp;lt;- -23.517227011061372
crs(map2) &amp;lt;- &amp;quot;+proj=longlat +datum=WGS84&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This part is the main piece of work. But after it’s done, you’ve got yourself a geo-referenced image. Here, we’ll write it to the geo-tiff format I mentioned earlier.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;writeRaster(map1, &amp;quot;Gmap1.tiff&amp;quot;, &amp;quot;GTiff&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Simple! :smiling_imp:&lt;/p&gt;


&lt;!-- BLOGDOWN-HEAD




/BLOGDOWN-HEAD --&gt;
</description>
    </item>
    
    <item>
      <title>Easier web scraping in R</title>
      <link>/easier-web-scraping-in-r.html</link>
      <pubDate>Fri, 05 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>/easier-web-scraping-in-r.html</guid>
      <description>&lt;!-- BLOGDOWN-BODY-BEFORE

/BLOGDOWN-BODY-BEFORE --&gt;

&lt;p&gt; &lt;/p&gt;
&lt;p&gt;In an earlier &lt;a href=&#34;http://robertmyles.github.io//Web-Navigation-and-Scraping-with-R.html&#34;&gt;post&lt;/a&gt;, I described some ways in which you can interact with a web browser using R and &lt;code&gt;RSelenium&lt;/code&gt;. This is ideal when you need to access data through drop-down menus and search bars. However, working with &lt;code&gt;RSelenium&lt;/code&gt; can be tricky. There are, of course, easier ways to get information from the internet using R.&lt;/p&gt;
&lt;p&gt;Perhaps the most straightforward way is to use &lt;code&gt;rvest&lt;/code&gt;, in tandem with other packages of the &lt;a href=&#34;https://barryrowlingson.github.io/hadleyverse/#1&#34;&gt;Hadleyverse&lt;/a&gt;&lt;sup id=&#34;a1&#34;&gt;&lt;a href=&#34;#fn1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;, such as &lt;code&gt;dplyr&lt;/code&gt; and &lt;code&gt;tidyr&lt;/code&gt; for data preparation and cleaning after the webscrape. I’m going to use a simple example that I came across recently in my work, getting the name of each mayor in Brazil.&lt;/p&gt;
&lt;p&gt;Finding out who was &lt;em&gt;elected&lt;/em&gt; to the mayor’s office in each municipality in Brazil is easy: that data exists and is available on the &lt;a href=&#34;http://www.tse.jus.br/&#34;&gt;website&lt;/a&gt; of the &lt;em&gt;Tribunal Superior Eleitoral&lt;/em&gt;. However, just because someone was elected to office (in this case in 2014) does not mean that they are still in office now, two years later. After searching around the web for a bit, I realised that this data is not available as a dataset.&lt;/p&gt;
&lt;p&gt;After wandering to the website of the &lt;a href=&#34;http://www.ibge.gov.br/home/&#34;&gt;IBGE&lt;/a&gt;, a Brazilian statistics agency, I found a way to get the name of the mayor currently in charge of each municipality. Each municipality has its own webpage on the IGBE’s dedicated &lt;a href=&#34;http://www.cidades.ibge.gov.br/xtras/home.php&#34;&gt;Cidades@&lt;/a&gt; site.&lt;/p&gt;
&lt;p&gt;For example, you will see the a webpage for the municipality of Acrelândia, shown in the image below. As you can see, the name of the mayor (“Prefeito”) is on the right-hand side of the page. Since we now know we can get this for each municipality, we have three tasks to do in order to get this info into R:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;find out what part of the url changes as we move from city to city on the website;&lt;/li&gt;
&lt;li&gt;send the corresponding information to the server using R;&lt;/li&gt;
&lt;li&gt;scrape the page and tidy up the resulting data in R.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://i.imgur.com/MGqKffr.png&#34; style=&#34;width:750px;height:500px;&#34;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;The url for &lt;a href=&#34;http://www.cidades.ibge.gov.br/xtras/perfil.php?lang=&amp;amp;codmun=120001&amp;amp;search=acre%7Cacrelandia&#34;&gt;Acrelândia&lt;/a&gt; is unique at: “codmun=120001” and “search=acre|acrelandia”.&lt;br /&gt;
The number in “codmun” is available as the IBGE municipal code (although missing the final digit, strangely…but that’s not a problem, we just take it off the end for each one) and the rest is just the state and the municipality, all information that is easy to get from various sources. For this example, I’ve uploaded this basic dataset to Github so we can use it here.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
library(tidyr)
library(readr)
library(stringr)
library(stringi)
library(rvest)

## read in data and create variables for webscraping:
Mayors &amp;lt;- read_csv(&amp;quot;https://raw.githubusercontent.com/RobertMyles/RobertMyles.github.io/master/_data/IBGE_codes.csv&amp;quot;) %&amp;gt;% 
  select(-c(UF, Cod.Mun)) %&amp;gt;% 
  dplyr::rename(Code_IBGE = Cod.IBGE) %&amp;gt;% 
  mutate(MUNIC2 = tolower(.$MUNIC)) %&amp;gt;% 
  mutate(MUNIC2 = gsub(&amp;quot; &amp;quot;, &amp;quot;-&amp;quot;, .$MUNIC2)) %&amp;gt;% 
  mutate(Name_UF2 = tolower(.$Name_UF)) %&amp;gt;% 
  mutate(Code2 = unlist(str_extract_all(.$Code_IBGE, &amp;quot;[0-9]{6}&amp;quot;))) %&amp;gt;% 
  unite(col = Link, Name_UF2, MUNIC2, sep = &amp;quot;|&amp;quot;, remove = F) %&amp;gt;% 
  arrange(ACR_UF) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;  In the code snippet above, we’ve taken out unnecessary columns, renamed one, changed the names of the municipalities to lower case (for the url), taken six numbers of the IBGE code for use in the webscrape and joined the state and municipality names together, with &lt;code&gt;|&lt;/code&gt; seperating them, as in the url for each municipality webpage. We also need to create some empty data frames to fill, and remove the municipality of Brasília, which does not have a &lt;em&gt;Prefeito&lt;/em&gt;, just a &lt;a href=&#34;http://www.cidades.ibge.gov.br/xtras/perfil.php?lang=&amp;amp;codmun=530010&amp;amp;search=distrito-federal%7Cbrasilia&#34;&gt;governor&lt;/a&gt;, which is all done below:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;url &amp;lt;- &amp;quot;http://www.cidades.ibge.gov.br/xtras/perfil.php?lang=&amp;amp;codmun=&amp;quot;

link &amp;lt;- Mayors$Link
grep(&amp;quot;distrito federal|brasilia&amp;quot;, link)
link &amp;lt;- link[-804]
link2 &amp;lt;- Mayors$Code2
link2 &amp;lt;- link2[-804]

Prefeitos &amp;lt;- data.frame()
Cidades &amp;lt;- data.frame()
Pref &amp;lt;- data.frame()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next comes our webscrape, which is incredibly easy with &lt;code&gt;rvest&lt;/code&gt; (&lt;code&gt;xml2&lt;/code&gt; is likewise easy). The only hard part of this entire scrape is getting the words “Prefeito” along with the name of the mayor out of the document. This relies on regex, which can be tricky. But trial and error should lead you to the right answer for whatever you need. Or search &lt;a href=&#34;http://www.rexegg.com/regex-quickstart.html&#34;&gt;Google&lt;/a&gt;, of course.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;for(i in 1:length(link)){
  URL &amp;lt;- paste(url, link2[i], &amp;quot;&amp;amp;search=&amp;quot;, link[i], sep = &amp;quot;&amp;quot;)
  pref &amp;lt;- read_html(URL)
  pref1 &amp;lt;- html_nodes(pref, xpath = &amp;#39;//*[@id=&amp;quot;mod_perfil_infosbasicas&amp;quot;]&amp;#39;)
  str &amp;lt;- html_text(pref1)
  str1 &amp;lt;- unlist(str_extract_all(str, &amp;quot;Prefeito[\\w A-Z]*&amp;quot;))
  print(str1)
  Prefeitos &amp;lt;- rbind(Prefeitos, str1, stringsAsFactors = F)
  City &amp;lt;- link[i]
  Cidades &amp;lt;- rbind(Cidades, City, stringsAsFactors = F)
  Pref &amp;lt;- cbind(Prefeitos, Cidades)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With a little tidying, we have a nice little dataset of each current mayors for each municipality in Brazil.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;colnames(Pref) &amp;lt;- c(&amp;quot;Prefeito&amp;quot;, &amp;quot;Municipio&amp;quot;) 
Pref$Prefeito &amp;lt;- gsub(&amp;quot;Prefeito&amp;quot;, &amp;quot;&amp;quot;, Pref$Prefeito)
Pref$Prefeito &amp;lt;- stri_trans_general(Pref$Prefeito, &amp;quot;Latin-ASCII&amp;quot;)
Pref1 &amp;lt;- Pref 
Pref1$Municipio &amp;lt;- Pref1$Municipio %&amp;gt;% 
  str_split_fixed(&amp;quot;\\|&amp;quot;, n = 2) %&amp;gt;% 
  toupper()
Pref$Name_UF &amp;lt;- Pref1$Municipio[,1]
Pref$MUNIC &amp;lt;- Pref1$Municipio[,2]
Pref &amp;lt;- select(Pref, -Municipio)
Mayors$MUNIC &amp;lt;- gsub(&amp;quot;[-]&amp;quot;, &amp;quot; &amp;quot;, Mayors$MUNIC)
Pref$MUNIC &amp;lt;- gsub(&amp;quot;[-]&amp;quot;, &amp;quot; &amp;quot;, Pref$MUNIC)
rm(Pref1)

Prefeitos &amp;lt;- full_join(Mayors, Pref)

Prefeitos &amp;lt;- select(Prefeitos, -c(Link, MUNIC2, Name_UF2, Code2))
Prefeitos &amp;lt;- Prefeitos[,c(1:5, 7, 6)]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://i.imgur.com/TRMOSkV.png&#34; style=&#34;width:650px;height:400px;&#34;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;b id=&#34;fn1&#34;&gt;1&lt;/b&gt; Supposedly, Hadley Wickham doesn’t actually like this term, but I’ll use it anyway, I’m sure he wouldn’t mind :smiley:. &lt;a href=&#34;#a1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;link rel=&#34;image_src&#34; href=&#34;http://i.imgur.com/VuCDpaX.png?1&#34; /&gt;&lt;/p&gt;


&lt;!-- BLOGDOWN-HEAD




/BLOGDOWN-HEAD --&gt;
</description>
    </item>
    
    <item>
      <title>Bayesian IRT in R and Stan</title>
      <link>/bayesian-irt-in-r-and-stan.html</link>
      <pubDate>Sat, 21 May 2016 00:00:00 +0000</pubDate>
      
      <guid>/bayesian-irt-in-r-and-stan.html</guid>
      <description>&lt;!-- BLOGDOWN-BODY-BEFORE

/BLOGDOWN-BODY-BEFORE --&gt;

&lt;p&gt;&lt;img src=&#34;http://i.imgur.com/v7y6SVt.png?3&#34; align=&#34;middle&#34; style=&#34;width:300px; height:250px;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The code below on Stan is also available as an &lt;a href=&#34;http://rpubs.com/RobertMylesMc/Bayesian-IRT-ideal-points-with-Stan-in-R&#34;&gt;&lt;code&gt;RPub webpage&lt;/code&gt;&lt;/a&gt;, if you’d rather work through the examples than read all of the post.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;One of the first areas where Bayesian modelling gained an entry point into the social sciences (and in particular political science) was in the area of legislator ideal points, with the use of the Item-Response Theory (IRT) models from the educational testing literature in psychology. This topic proved to be the perfect subject for the comparison of Bayesian and frequentist methods, since ideal point creation usually depends on nominal voting data, which may contain a lot of missing data (legislators who miss votes or abstain) and a huge number of parameters (hundreds of roll-calls by hundreds of legislators). The benefits of Bayesian methods over frequentist techniques for ideal point analysis is discussed at length elsewhere&lt;sup id=&#34;a1&#34;&gt;&lt;a href=&#34;#fn1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;, but here I’ll talk about a side-effect of using Bayesian methods for creating ideal points from roll-call data, that is, the long time it can take to run these models on a desktop computer. (In the following discussion, I refer to ‘legislators’, but these IRT models apply to all types of response to a question, whether the ‘question’ is a vote by a politician or a judge or questions on a test or survey.)&lt;/p&gt;
&lt;p&gt;To create ideal points in &lt;code&gt;R&lt;/code&gt;, you have three or four main options if you want to use ol’ &lt;a href=&#34;http://robertmyles.github.io//Books-on-Bayes-Stats.html&#34;&gt;Bayes&lt;/a&gt;. First, there is the ready-made &lt;bdi style=&#34;font-family:courier; color:#011a99&#34;&gt;ideal()&lt;/bdi&gt; command of the package &lt;a href=&#34;https://cran.r-project.org/web/packages/pscl/index.html&#34;&gt;pscl&lt;/a&gt; by Simon Jackman &amp;amp; co. &lt;code&gt;pscl&lt;/code&gt; includes some very handy little functions for those interested in generating ideal points from legislative voting data – summary statistics and plots are all easy to make, and come ready-made, such as party loyalty statistics, for example. However, &lt;bdi style=&#34;font-family:courier; color:#011a99&#34;&gt;ideal()&lt;/bdi&gt; suffers somewhat from being so ‘ready’: it is a bit unsuited for more complex or indivualistic models compared to some of the options mentioned later. I’ve also repeatedly run into problems with &lt;bdi style=&#34;font-family:courier; color:#011a99&#34;&gt;ideal()&lt;/bdi&gt; when trying to use some of the &lt;code&gt;pscl&lt;/code&gt; package options (&lt;bdi style=&#34;font-family:courier; color:#011a99&#34;&gt;dropList()&lt;/bdi&gt;, for example), or when estimating multidimensional models. In terms of &lt;a href=&#34;https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo&#34;&gt;MCMC&lt;/a&gt;, only one chain at a time may be run. In fact, it is what it says on the tin: it’s a Bayesian version of W-NOMINATE, which means it has the advantages of that program (easy to use) and the disadvantages (when it doesn’t work you’re not sure why…a bit ‘black-box’).&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;MCMCpack&lt;/code&gt; package also allows for the creation of ideal points, although its output is slightly less friendly to the beginner (an &lt;bdi style=&#34;font-family:courier; color:#011a99&#34;&gt;mcmclist&lt;/bdi&gt; object). Its &lt;bdi style=&#34;font-family:courier; color:#011a99&#34;&gt;MCMCirt1d()&lt;/bdi&gt; command is pretty similar to &lt;bdi style=&#34;font-family:courier; color:#011a99&#34;&gt;ideal()&lt;/bdi&gt; but allows for setting ‘soft’ constraints rather than the spike prior that pscl uses to pin down the position of (at least) two legislators. This is better for two reasons, in my opinion. First, it avoids a hard constraint on legislators for legislatures in which we do not have strong &lt;em&gt;a priori&lt;/em&gt; evidence to suppose that, for example, Legislator X is an extremist to the right, or Legislator Y to the left (the use of extremist legislators on either end of the supposed scale ‘anchors’ it). With &lt;code&gt;MCMCpack&lt;/code&gt;, the ideal points of the constrained legislators are drawn from a truncated normal distribution (truncated at zero) and so Legislator X (our extremist to the right) simply cannot have an ideal point on the left side of the scale and the opposite for our left-side extremist legislator (the use of these soft constraints obviates the need for them actually &lt;em&gt;being&lt;/em&gt; extremists too). I’ve also found &lt;code&gt;MCMCpack&lt;/code&gt; to be faster, although I haven’t tested that formally. In either case, both functions are quite similar. &lt;code&gt;MCMCpack&lt;/code&gt; also has functions for dynamic models, robust &amp;amp; multidimensional models, and Ordinal IRT. They’ve all worked well for me with the exception of &lt;bdi style=&#34;font-family:courier; color:#011a99&#34;&gt;MCMCirtkd()&lt;/bdi&gt;, the multidimensional model function, which never seems to get started.&lt;/p&gt;
&lt;p&gt;The next option is to use the &lt;code&gt;BUGS&lt;/code&gt; modelling language, either with &lt;code&gt;BUGS&lt;/code&gt; itself or its cousin &lt;code&gt;JAGS&lt;/code&gt;, both of which have been heavily used in the literature but can be &lt;strong&gt;extremely&lt;/strong&gt; slow, for reasons outlined in &lt;a href=&#34;http://robertmyles.github.io//Stan-JAGS.html&#34;&gt;this blog post&lt;/a&gt;. I don’t recommend their use for ideal points.&lt;/p&gt;
&lt;p&gt;Next, we have &lt;a href=&#34;http://mc-stan.org/&#34;&gt;Stan&lt;/a&gt;, which doesn’t have the simpler syntax of &lt;code&gt;JAGS&lt;/code&gt; &amp;amp; &lt;code&gt;BUGS&lt;/code&gt;, but is simply incomparably better in terms of speed. However, since it’s newer, you won’t find the amount of resources available for &lt;code&gt;BUGS&lt;/code&gt;, for example (like &lt;a href=&#34;https://www.jstatsoft.org/article/view/v036c01&#34;&gt;here&lt;/a&gt;). There are a few resources: a simple one-dimensional model can be seen on Pablo Barberá’s &lt;a href=&#34;https://github.com/pablobarbera/quant3materials/blob/master/bayesian/lab14_IRT_issues.R&#34;&gt;github&lt;/a&gt;; a friend of mine, Guilherme Duarte, has an example of a dynamic model on his github &lt;a href=&#34;https://github.com/duarteguilherme/Quinn-Martin-Replication&#34;&gt;too&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;There are some other resources available, but relate to slightly different IRT models, more common in the educational-testing literature, and less so in ideal point studies: the ‘Rasch’ &lt;a href=&#34;http://www.stat.columbia.edu/~gelman/research/unpublished/stan_v_stata.pdf&#34;&gt;model&lt;/a&gt;; the &lt;a href=&#34;https://rpubs.com/rfarouni/64284&#34;&gt;2PL model&lt;/a&gt; (in which a ‘yes’ answer has a specific associated movement in the dimensional space and the discrimination parameter only takes on postive values; in the ideal-point model of &lt;a href=&#34;https://www.cs.princeton.edu/courses/archive/fall09/cos597A/papers/Jackman2001.pdf&#34;&gt;Jackman&lt;/a&gt; it can possess negative and positive values).&lt;/p&gt;
&lt;p&gt;Since there are so few Stan resources for ideal point IRT models, I thought I’d post a few models here. The code is also available as an &lt;a href=&#34;http://rpubs.com/RobertMylesMc/Bayesian-IRT-ideal-points-with-Stan-in-R&#34;&gt;RPub webpage&lt;/a&gt;, as mentioned earlier. The statistical model we’ll employ is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_{ij} = \beta_j\bf{x_i} - \alpha_j,\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where (&lt;span class=&#34;math inline&#34;&gt;\(y_{ij}\)&lt;/span&gt; are the votes, in binary form (1 = ‘Yes’; 2 = ‘No’); the &lt;span class=&#34;math inline&#34;&gt;\(\bf x_i\)&lt;/span&gt; are the ideal points of the legislators; and &lt;span class=&#34;math inline&#34;&gt;\(\beta_j\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\alpha_j\)&lt;/span&gt; are the discrimination and difficulty parameters of the model.&lt;/p&gt;
&lt;p&gt;Starting from scratch in &lt;code&gt;R&lt;/code&gt; in a new session (you’ll need a C++ compiler if you don’t have one, see &lt;a href=&#34;https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started&#34;&gt;here&lt;/a&gt;):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(&amp;quot;RStan&amp;quot;)
library(&amp;quot;RStan&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ideal points are created from a &lt;em&gt;j&lt;/em&gt; &lt;span class=&#34;math inline&#34;&gt;\(\times\)&lt;/span&gt; &lt;em&gt;m&lt;/em&gt; matrix of voting data (&lt;em&gt;j&lt;/em&gt; legislators voting on &lt;em&gt;m&lt;/em&gt; votes), coded &lt;bdi style=&#34;font-family:courier&#34;&gt;1&lt;/bdi&gt; for ‘yes’ and &lt;bdi style=&#34;font-family:courier&#34;&gt;0&lt;/bdi&gt; for ‘no’ and abstentions. Missing data are &lt;bdi style=&#34;font-family:courier&#34;&gt;NA&lt;/bdi&gt;, and are deleted out before running in Stan. We can easily simulate data for this type of thing, but let’s use a real database. This data is from the 53rd legislature of the Brazilian Federal Senate (with thanks to &lt;a href=&#34;http://www.cebrap.org.br/v2/pages/home&#34;&gt;CEBRAP&lt;/a&gt;, who built the original database, this comes from an extended version I created), we’ll download it from my Github repo. You’ll need to install &lt;code&gt;readr&lt;/code&gt; if you don’t have it. (I also have the bad habit of naming my data as “data”… not generally a great idea. It’ll be ok here, though.)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(readr)
data &amp;lt;- read_csv(&amp;quot;https://raw.githubusercontent.com/RobertMyles/Bayesian-Ideal-Point-IRT-Models/master/Senate_Example.csv&amp;quot;)
colnames(data)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So let’s take a look at the data. You’ll see the column names are “VoteNumber”, “SenNumber”, “SenatorUpper”, “Vote”, “Party”, “GovCoalition”, “State”, “FP”, “Origin”, “Contentious”, “IndGov”, and “VoteType”. I’ve kept them in this state so that we can tidy things up and manipulate things a little, stuff you’ll probably have to do any time you deal with real data of this sort. We can also have a look later at different plotting options using some of these variables. First, let’s change the votes, which are in the format “S” (&lt;em&gt;Sim&lt;/em&gt;, ‘Yes’), “N” (‘No’), “A” (Abstention), and “O” (Obstruction), to numeric format.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data$Vote[data$Vote==&amp;quot;S&amp;quot;] &amp;lt;- 1
data$Vote[data$Vote==&amp;quot;N&amp;quot;] &amp;lt;- 0
data$Vote[data$Vote  %in% c(NA,&amp;quot;O&amp;quot;,&amp;quot;A&amp;quot;)] &amp;lt;- NA
data$Vote &amp;lt;- as.numeric(data$Vote)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;Next, we’ll create the ‘vote matrix’. This is the &lt;em&gt;j&lt;/em&gt; &lt;span class=&#34;math inline&#34;&gt;\(\times\)&lt;/span&gt; &lt;em&gt;m&lt;/em&gt; matrix that we will use to create the ideal points with Stan. The rows will be the legislators and the columns the votes. We will also need to deal with the issue of &lt;a href=&#34;http://polmeth.wustl.edu/files/polmeth/river03.pdf&#34;&gt;‘constraints’&lt;/a&gt;: we need to identify &lt;em&gt;d(d + 1)&lt;/em&gt; legislators in &lt;em&gt;d&lt;/em&gt; dimensions and constrain their ideal points in some way. For now, we’ll just organise our vote matrix in such a way that the two legislators that will be constrained are placed in rows 1 and 2 of the matrix. For this example, we can use Senators Agripino and Suplicy, who belong to two parties that are generally considered to be on opposite sides of the political ‘space’ that we will place our ideal points upon. Organizing things in this way is not necessary but makes the Stan model code cleaner later on.&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data$FullID &amp;lt;- paste(data$SenatorUpper, data$Party, sep=&amp;quot;:&amp;quot;)
NameID &amp;lt;- unique(data$FullID)
J &amp;lt;- length(unique(NameID))
M &amp;lt;- length(unique(data$VoteNumber))
grep(&amp;quot;JOSE AGRIPINO:PFL&amp;quot;, NameID)  #34
grep(&amp;quot;EDUARDO SUPLICY:PT&amp;quot;, NameID) #12
NameID &amp;lt;- NameID[c(34, 12, 1:11, 13:33, 35:J)]

y &amp;lt;- matrix(NA,J,M)
Rows &amp;lt;- match(data$FullID, NameID)
Cols &amp;lt;- unique(data$VoteNumber)
Columns &amp;lt;- match(data$VoteNumber, Cols)

for(i in 1:dim(data)[1]){
  y[Rows[i],Columns[i]] &amp;lt;- data$Vote[i]
}

dimnames(y) &amp;lt;- list(unique(NameID), unique(data$VoteNumber))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I presume you’re using RStudio. Clicking on the viewer should show you the vote matrix, which should look like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://i.imgur.com/iOh3lfY.png?1&#34;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;Next we’ll make a dataframe of legislator variables which we’ll use later on, and one of vote characteristics.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ldata &amp;lt;- data.frame(FullID = unique(NameID), 
                    Party = data$Party[match(unique(NameID), 
                                             data$FullID)], 
                    GovCoalition = data$GovCoalition[match(unique(NameID),
                                                           data$FullID)],
                    Name = data$SenatorUpper[match(unique(NameID), 
                                                   data$FullID)], 
                    State = data$State[match(unique(NameID), 
                                             data$FullID)], 
                    row.names = NULL, 
                    stringsAsFactors = FALSE)

vdata &amp;lt;- data.frame(VoteNumber = unique(data$VoteNumber), 
                    VoteType = data$VoteType[match(unique(data$VoteNumber),
                                                   data$VoteNumber)],
                    SenNumber = data$SenNumber[match(unique(data$VoteNumber),
                                                     data$VoteNumber)],
                    Origin = data$Origin[match(unique(data$VoteNumber),
                                               data$VoteNumber)],
                    Contentious = data$Contentious[match(unique(data$VoteNumber),
                                                         data$VoteNumber)], 
                    IndGov = data$IndGov[match(unique(data$VoteNumber),
                                               data$VoteNumber)],
                    stringsAsFactors = F)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;Stan is not like &lt;code&gt;JAGS&lt;/code&gt; and &lt;code&gt;BUGS&lt;/code&gt; in that &lt;bdi style=&#34;font-family:courier&#34;&gt;NA&lt;/bdi&gt; is unwieldy to incorporate. The best thing to do is to delete missing data out, as can be seen in Barberá’s script linked to earlier, which I’ll copy here.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;N &amp;lt;- length(y)
j &amp;lt;- rep(1:J, times=M)
m &amp;lt;- rep(1:M, each=J)

miss &amp;lt;- which(is.na(y))
N &amp;lt;- N - length(miss)
j &amp;lt;- j[-miss]
m &amp;lt;- m[-miss]
y &amp;lt;- y[-miss]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we’ll set our initial values. There are various ways to do this, ranging from leaving it up to Stan (i.e. not setting any values) to creating lists with specific starting values for each parameter. What we’ll do here is use the starting values as a way to start the parties off in separate places. This has several advantages: we already know that these parties don’t vote together very often (i.e., they are parties of the government and the opposition) and so we can speed up the model by starting the legislators off where we already know they’ll be (i.e. right-wing parties on the right etc.). This also has the benefit of making it less likely that we’ll end up with ‘sign-flips’, where a legislator with a bi-modal posterior distribution has an ideal point from the ‘wrong’ mode.&lt;sup id=&#34;a2&#34;&gt;&lt;a href=&#34;#fn2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; For the discrimination and difficulty paramters, we’ll use a random sample from normal distributions. We’ll also save all this information as &lt;code&gt;stan.data&lt;/code&gt;, which is the list of data we’ll use with Stan.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ldata$ThetaStart &amp;lt;- rnorm(J, 0, 1)
ldata$ThetaStart[ldata$Party==&amp;quot;PFL&amp;quot; | ldata$Party==&amp;quot;PTB&amp;quot; | ldata$Party==&amp;quot;PSDB&amp;quot; | ldata$Party==&amp;quot;PPB&amp;quot;] &amp;lt;- 2
ldata$ThetaStart[ldata$Party==&amp;quot;PT&amp;quot; | ldata$Party==&amp;quot;PSOL&amp;quot; | ldata$Party==&amp;quot;PCdoB&amp;quot;] &amp;lt;- -2
ThetaStart &amp;lt;- ldata$ThetaStart

initF &amp;lt;- function() {
  list(theta=ThetaStart, beta=rnorm(M, 0, 2), alpha=rnorm(M, 0, 2))
}

stan.data &amp;lt;- list(J=J, M=M, N=N, j=j, m=m, y=y, ThetaStart=ThetaStart)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;Stan model code differs from those mentioned above in a few aspects. Firstly, variables need to be declared, along with their type. For example, &lt;em&gt;J&lt;/em&gt;, which is our index for the number of senators, is declared in the following code as an integer. The parameters are likewise declared, as real numbers. The model code has three blocks: data, parameters and the model itself (there are other blocks possible, such as&lt;bdi style=&#34;font-family:courier; color:#011a99&#34;&gt;generated data&lt;/bdi&gt;, see the Stan &lt;a href=&#34;http://mc-stan.org/documentation/&#34;&gt;manual&lt;/a&gt;. Stan code is also imperative – the order of the blocks matters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stan.code &amp;lt;- &amp;quot;
    data {
    int&amp;lt;lower=1&amp;gt; J; //Senators
    int&amp;lt;lower=1&amp;gt; M; //Proposals
    int&amp;lt;lower=1&amp;gt; N; //no. of observations
    int&amp;lt;lower=1, upper=J&amp;gt; j[N]; //Senator for observation n
    int&amp;lt;lower=1, upper=M&amp;gt; m[N]; //Proposal for observation n
    int&amp;lt;lower=0, upper=1&amp;gt; y[N]; //vote of observation n
    }
    parameters {
    real alpha[M];
    real beta[M];
    real theta[J];
    }
    model {
    alpha ~ normal(0,5); 
    beta ~ normal(0,5); 
    theta ~ normal(0,1); 
    theta[1] ~ normal(1, .01);
    theta[2] ~ normal(-1, .01);  
    for (n in 1:N)
    y[n] ~ bernoulli_logit(theta[j[n]] * beta[m[n]] - alpha[m[n]]);
    }&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;This IRT model can be run using either the logistic or probit link function, however, since Stan has a built in &lt;bdi style=&#34;font-family:courier; color:#011a99&#34;&gt;bernoulli_logit&lt;/bdi&gt;, we’ll use that. You can see from the model block above that we have specified specific prior distributions for &lt;bdi style=&#34;font-family:courier; color:#011a99&#34;&gt;theta[1]&lt;/bdi&gt; and &lt;bdi style=&#34;font-family:courier; color:#011a99&#34;&gt;theta[2]&lt;/bdi&gt;. These are our constrained legislators – Agripino and Suplicy. We can do this using truncated normal distributions in Stan (i.e. &lt;bdi style=&#34;font-family:courier; color:#011a99&#34;&gt;theta[1] ~ normal(1, .01)T[0,]&lt;/bdi&gt;, for example), but in my experience this makes things slower and increases the number of divergent transitions reported by Stan. We then use the &lt;code&gt;stan()&lt;/code&gt; command to run our model in Stan. Here, I’m using 1000 iterations just to show (as it doesn’t take too long); these IRT models generally need more iterations than other models, for good estimates from this data, I run 5000 iterations with 2500 burn-in. A couple of hundred iterations usually suffices in Stan, depending on the model. The number of chains and cores are linked to what I have available on my computer. You can check this with the parallel package using &lt;bdi style=&#34;font-family:courier; color:#011a99&#34;&gt;detectCores()&lt;/bdi&gt;. A quick way to check convergence of the chains is with a graph of Rhat, shown below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stan.fit &amp;lt;- stan(model_code=stan.code, data=stan.data, iter=3000, 
                 warmup=1500, chains=4, thin=5, init=initF, 
                 verbose=TRUE, cores=4, seed=1234)

stan_rhat(stan.fit, bins=60)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://i.imgur.com/YNBevMV.png?1&#34;&gt;&lt;/p&gt;
&lt;p&gt;Values of Rhat should be 1.03 or lower. As you can see, even from 1000 iterations, we can be confident these chains are converging.&lt;/p&gt;
&lt;div id=&#34;graphing-ideal-points&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Graphing Ideal Points&lt;/h2&gt;
&lt;p&gt;I find the best way to plot ideal points is by using ggplot2. It’s automatically loaded as part of rstan. I also prefer to use an mcmc.list object, simply because I’m more used to it. But you can use the &lt;bdi style=&#34;font-family:courier; color:#011a99&#34;&gt;stan.fit&lt;/bdi&gt; object directly if you prefer.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;MS &amp;lt;- As.mcmc.list(stan.fit)
sMS &amp;lt;- summary(MS)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are various things we can plot from the summary above. Of main interest is usually the ideal points, so we’ll start with those first. First, let’s extract the ideal points (“theta”) from the summary, along with the lower and upper ends of the 95% credible interval:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Theta &amp;lt;- sMS$statistics[grep(&amp;quot;theta&amp;quot;, row.names(sMS$statistics)),1]
ThetaQ &amp;lt;- sMS$quantiles[grep(&amp;quot;theta&amp;quot;, row.names(sMS$statistics)),c(1,5)]
Theta &amp;lt;- as.data.frame(cbind(Theta, ThetaQ))
rm(ThetaQ)
Theta$FullID &amp;lt;- ldata$FullID
row.names(Theta) &amp;lt;- NULL
colnames(Theta)[1:3] &amp;lt;- c(&amp;quot;Mean&amp;quot;, &amp;quot;Lower&amp;quot;, &amp;quot;Upper&amp;quot;)
Theta &amp;lt;- merge(Theta, ldata, by=&amp;quot;FullID&amp;quot;)
Theta &amp;lt;- Theta[order(Theta$Mean),]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we have a dataframe of legislator characteristics alng with their ideal points. Since we’re dealing with a one-dimensional model here, the most straight-forward way to plot is along a scale ranging from the lowest ideal point to the highest. Here, I’ll colour the ideal points and their intervals by membership of the government coalition. I’ve used some other plotting options to make this plot the way I like it, but it’s easy to change things to your taste in ggplot2.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Y &amp;lt;- seq(from=1, to=length(Theta$Mean), by=1)

ggplot(Theta, aes(x=Mean, y=Y)) + 
  geom_point(aes(colour=GovCoalition),
             shape=19, size=3) + 
  geom_errorbarh(aes(xmin = Lower, xmax = Upper,colour = GovCoalition), 
                 height = 0) + 
  geom_text(aes(x = Upper, label = FullID, colour = GovCoalition), 
            size = 2.5, hjust = -.05) + 
  scale_colour_manual(values = c(&amp;quot;red&amp;quot;, &amp;quot;blue&amp;quot;)) +
  theme(axis.text.y = element_blank(), 
        axis.ticks.y = element_blank(), 
        axis.title = element_blank(), 
        legend.position = &amp;quot;none&amp;quot;, 
        panel.grid.major.y = element_blank(),
        panel.grid.major.x = element_line(linetype = 1, 
                                          colour = &amp;quot;grey&amp;quot;),
        panel.grid.minor = element_blank(),  
        panel.background = element_rect(fill = &amp;quot;white&amp;quot;), 
        panel.border = element_rect(colour = &amp;quot;black&amp;quot;, fill = NA, 
                                    size = .4)) +
  scale_x_continuous(limits = c(-2.7, 4))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://i.imgur.com/fE2LY5L.png?1&#34;&gt;&lt;/p&gt;
&lt;p&gt;Of course, that’s not all the information we have in our ldata dataframe. We could plot things by party or by state. Let’s plot something by region (since there are a lot of states):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;St &amp;lt;- Theta[is.na(Theta$State)==FALSE,]  # take out president
St$Region &amp;lt;- NA
SE &amp;lt;- c(&amp;quot;SP&amp;quot;, &amp;quot;RJ&amp;quot;, &amp;quot;ES&amp;quot;, &amp;quot;MG&amp;quot;)
S &amp;lt;- c(&amp;quot;RS&amp;quot;, &amp;quot;PR&amp;quot;, &amp;quot;SC&amp;quot;)
N &amp;lt;- c(&amp;quot;AM&amp;quot;, &amp;quot;RO&amp;quot;, &amp;quot;RR&amp;quot;, &amp;quot;TO&amp;quot;, &amp;quot;PA&amp;quot;, &amp;quot;AC&amp;quot;, &amp;quot;AP&amp;quot;)
CW &amp;lt;- c(&amp;quot;DF&amp;quot;, &amp;quot;GO&amp;quot;, &amp;quot;MT&amp;quot;, &amp;quot;MS&amp;quot;)
NE &amp;lt;- c(&amp;quot;CE&amp;quot;, &amp;quot;MA&amp;quot;, &amp;quot;AL&amp;quot;, &amp;quot;RN&amp;quot;, &amp;quot;PB&amp;quot;, &amp;quot;SE&amp;quot;, &amp;quot;PI&amp;quot;, &amp;quot;BA&amp;quot;, &amp;quot;PE&amp;quot;)
St$Region[St$State %in% SE] &amp;lt;- &amp;quot;South-East&amp;quot;
St$Region[St$State %in% S] &amp;lt;- &amp;quot;South&amp;quot;
St$Region[St$State %in% NE] &amp;lt;- &amp;quot;North-East&amp;quot;
St$Region[St$State %in% CW] &amp;lt;- &amp;quot;Centre-West&amp;quot;
St$Region[St$State %in% N] &amp;lt;- &amp;quot;North&amp;quot;

nameorder &amp;lt;- St$FullID[order(St$Region, St$Mean)]
St$FullID &amp;lt;- factor(St$FullID, levels=nameorder)

ggplot(St, aes(x=Mean, y=FullID)) + 
  geom_point(size = 3, aes(colour = Region)) + 
  geom_errorbarh(aes(xmin = Lower, xmax = Upper, colour = Region), 
                 height = 0) + 
  facet_grid(Region ~ ., scales = &amp;quot;free_y&amp;quot;) +
  scale_colour_manual(values = c(&amp;quot;orange&amp;quot;, &amp;quot;black&amp;quot;, &amp;quot;red&amp;quot;, 
                                 &amp;quot;blue&amp;quot;, &amp;quot;darkgreen&amp;quot;)) + 
  theme_bw()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://i.imgur.com/M4sx2az.png?1&#34;&gt;&lt;/p&gt;
&lt;p&gt;We can also analyse the other parameters of the model, and run multidimensional models too. See the &lt;a href=&#34;http://rpubs.com/RobertMylesMc/Bayesian-IRT-ideal-points-with-Stan-in-R&#34;&gt;RPub&lt;/a&gt; for the code for these.&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;b id=&#34;fn1&#34;&gt;1&lt;/b&gt; There are many discussions on this topic, but &lt;a href=&#34;https://my.vanderbilt.edu/joshclinton/files/2011/10/CJ_LSQ2009.pdf&#34;&gt;Clinton &amp;amp; Jackman (2009)&lt;/a&gt; is a good place to start. An earlier &lt;a href=&#34;https://www.cs.princeton.edu/courses/archive/fall09/cos597A/papers/ClintonJackmanRivers2004.pdf&#34;&gt;paper&lt;/a&gt; by Clinton, Jackman &amp;amp; Rivers makes the point somewhat more forcefully. &lt;a href=&#34;#a1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;b id=&#34;fn2&#34;&gt;2&lt;/b&gt; For more on this point, see &lt;a href=&#34;https://www.cs.princeton.edu/courses/archive/fall09/cos597A/papers/Jackman2001.pdf&#34;&gt;Jackman&lt;/a&gt; 2001, &lt;a href=&#34;http://polmeth.wustl.edu/files/polmeth/river03.pdf&#34;&gt;Rivers 2003&lt;/a&gt; paper cited in the main text, or the Appendix of my PhD &lt;a href=&#34;http://robertmyles.github.io//assets/Explaining%20the%20Determinants%20of%20Foreign%20Policy%20Voting%20Behaviour%20in%20the%20Brazilian%20Houses%20of%20Legislature.pdf&#34;&gt;thesis&lt;/a&gt;. &lt;a href=&#34;#a2&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;link rel=&#34;image_src&#34; href=&#34;http://i.imgur.com/VuCDpaX.png?1&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;


&lt;!-- BLOGDOWN-HEAD




/BLOGDOWN-HEAD --&gt;
</description>
    </item>
    
    <item>
      <title>About</title>
      <link>/about/</link>
      <pubDate>Thu, 05 May 2016 21:48:51 -0700</pubDate>
      
      <guid>/about/</guid>
      <description>&lt;p&gt;This is a &amp;ldquo;hello world&amp;rdquo; example website for the &lt;a href=&#34;https://github.com/rstudio/blogdown&#34;&gt;&lt;strong&gt;blogdown&lt;/strong&gt;&lt;/a&gt; package. The theme was forked from &lt;a href=&#34;https://github.com/jrutheiser/hugo-lithium-theme&#34;&gt;@jrutheiser/hugo-lithium-theme&lt;/a&gt; and modified by &lt;a href=&#34;https://github.com/yihui/hugo-lithium-theme&#34;&gt;Yihui Xie&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Bayesian Stats -- Book Recommendations</title>
      <link>/books-on-bayes-stats.html</link>
      <pubDate>Tue, 03 May 2016 00:00:00 +0000</pubDate>
      
      <guid>/books-on-bayes-stats.html</guid>
      <description>&lt;!-- BLOGDOWN-BODY-BEFORE

/BLOGDOWN-BODY-BEFORE --&gt;

&lt;p&gt;The first time I came across Bayes’ Theorem&lt;sup id=&#34;a1&#34;&gt;&lt;a href=&#34;#fn1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;, I must admit I was pretty confused. It was in &lt;a href=&#34;http://www.amazon.com/Introductory-Statistics-9th-Neil-Weiss/dp/0321691229/ref=pd_cp_14_1?ie=UTF8&amp;amp;refRID=15HFJDGMBF49CXAD9W9S&#34;&gt;Introductory Statistics&lt;/a&gt; by Neil A. Weiss, the course book in a statistics course I was taking at the time. Neither the logic of it nor the formula for it made much sense to me. For somebody new to probability, I was still trying to figure out what the hell P(A) actually &lt;em&gt;meant&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;Looking back, the funny thing is that it is the branch of statistics that &lt;em&gt;isn’t&lt;/em&gt; wont to use Bayes’ Theorem that I find confusing.&lt;sup id=&#34;a2&#34;&gt;&lt;a href=&#34;#fn2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; Bayesian statistics now makes perfect sense to me. Indeed, it follows human intuition (even if the formula looks weird for anybody new to probability). The probability of the hypothesis we have in mind, given the data we observe (that would be the &lt;code&gt;P(A|B)&lt;/code&gt; part, but we can rewrite it as &lt;code&gt;Pr(Hypothesis|Data)&lt;/code&gt;; this is also called the &lt;em&gt;posterior&lt;/em&gt; ) is… what exactly?&lt;br /&gt;
Well, it’s a combination of the initial plausibility of our hypothesis (&lt;code&gt;P(A)&lt;/code&gt;, also called the &lt;em&gt;prior&lt;/em&gt; ), multiplied by what’s called the likelihood (&lt;code&gt;P(B|A)&lt;/code&gt;, or &lt;code&gt;Pr(Data|Hypothesis)&lt;/code&gt;), which is the data we would expect to see if our hypothesis were correct. The denominator is often called the ‘evidence’ or something similarly opaque, but it is merely the numerator plus its converse, that is to say, the probability that our original hypothesis is wrong by the likelihood of our data, assuming that our hypothesis is wrong. In any case, its function is just to make sure our probabilities sum to one, as they should.&lt;/p&gt;
&lt;p&gt;As you can see, all of those &lt;code&gt;P(|)&lt;/code&gt;s and &lt;code&gt;Pr&lt;/code&gt;s can make things confusing – underneath it all, it’s simpler. First of all, the &lt;code&gt;Pr()&lt;/code&gt; notation and the denominator are often left out, making the theorem look more like this:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[posterior \propto prior \centerdot likelihood.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The plausibility of our idea, now that we have seen data, is proportional to its original plausibility times the likelihood. Well, reasonably simpler, but the fact is that most people are not comfortable thinking in terms of probability. Given that Bayes’ Theorem is the basic foundation block for an entire body of statistical literature&lt;sup id=&#34;a3&#34;&gt;&lt;a href=&#34;#fn3&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;, one can see how things could get out of hand pretty quickly – hence the need for good books on the subject. I didn’t learn &lt;em&gt;any&lt;/em&gt; Bayesian statistics in any class I ever had, I learned everything I know (astoundingly little) from reading plenty of books, sometimes the whole way through, sometimes just certain parts until I got bored, from reading on the web, from making many mistakes in &lt;code&gt;R&lt;/code&gt; – gradually, I found my way and built my understanding of Bayesian stats. Given that I read (or skimmed) quite a lot of books on the topic, I thought I’d share my two cents on those I came across. There are certainly many more, depending on the specific area of the sciences or on the level of technicality assumed, but these are the ones that I read and either loved, liked somewhat, got bored, or simply got lost (some of them are waaay too difficult…at least for me). Let’s dive in. They’re in no particular order, by the way.&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
&lt;img src=&#34;http://i.imgur.com/b0EkBG5.jpg?1&#34;/&gt;
&lt;/p&gt;
&lt;p&gt;Probably the first book that comes to mind is one of the first that I read on the topic, Simon Jackman’s &lt;a href=&#34;http://onlinelibrary.wiley.com/book/10.1002/9780470686621&#34;&gt;Bayesian Analysis for the Social Sciences&lt;/a&gt;. Jackman’s book&lt;sup id=&#34;a4&#34;&gt;&lt;a href=&#34;#fn4&#34;&gt;4&lt;/a&gt;&lt;/sup&gt; has a nice introduction to the topic and the first few chapters are reasonably easy to follow. However, his mathematics are detailed and even a bit pedantic (nothing wrong with that in an academic book) and things can get heavy going &lt;em&gt;very&lt;/em&gt; quickly. Reading through derivations of the conjugacy of probability distributions convinced me I needed to a) go back and re-learn calculus &lt;em&gt;again&lt;/em&gt; (which I did), and b) go a little further back in the tree of books on Bayesian statistics.&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
&lt;img src=&#34;http://i.imgur.com/jpNFefC.png?1&#34;/&gt;
&lt;/p&gt;
&lt;p&gt;This led me down a few interesting paths, from de Finetti’s famous “PROBABILITY DOES NOT EXIST” statement, which I originally saw in Jackman’s book and then hunted down the original (I enjoyed the start quite a lot but then got bored), to learning &lt;code&gt;JAGS&lt;/code&gt; to go along with Jackman’s examples, to some rather unnecessary and heavy-going books (&lt;a href=&#34;http://link.springer.com/book/10.1007%2F978-1-4612-4024-2&#34;&gt;Tanner&lt;/a&gt;, for example). However, I decided to go the ‘source’ (in a modern context) and so I started reading Bernardo and Smith’s &lt;a href=&#34;http://onlinelibrary.wiley.com/book/10.1002/9780470316870&#34;&gt;Bayesian Theory&lt;/a&gt;, which really helped to give me a solid understanding of the concepts involved. It’s a detailed read, and well recommended if you want a deeper understanding of the concepts behind Bayesian statistics.&lt;/p&gt;
&lt;p&gt;Moving from concepts to application, I found Donald Berry’s &lt;a href=&#34;http://www.amazon.com/Statistics-Bayesian-Perspective-Donald-Berry/dp/0534234720&#34;&gt;Statistics: a Bayesian Perspective&lt;/a&gt; really useful for getting a grip on the basic elements. The book is a bit dated now, and is targeted at an undergraduate audience, which is actually something in its favour. Up until Kruschke and McElreath’s books (mentioned later), most Bayesian stats books seemed to be aimed at people who were already experts in statistics (or knowledgeable, at least), with the aim of convincing them why they should switch to Bayesian methods. As a result, a lot of these books dive headlong into subjects that are not appropriate for most students (see Jackman’s conjugacy discussions, above) and have the effect of turning a lot of students off the material. Berry’s book, although limited, does the opposite.&lt;/p&gt;
&lt;p&gt;There are other statistics books that cover Bayesian ideas, such as &lt;a href=&#34;http://www.amazon.com/Introduction-Bayesian-Statistics-William-Bolstad/dp/0470141158&#34;&gt;Bolstad’s&lt;/a&gt; (I personally didn’t like his style) and deGroot &amp;amp; Schervish’s well-known &lt;a href=&#34;https://www.pearsonhighered.com/program/De-Groot-Probability-and-Statistics-4th-Edition/PGM146802.html&#34;&gt;book&lt;/a&gt;, which is a fine book, but very dry for my taste. There are also other introductory Bayesian statistics books, such as those by &lt;a href=&#34;http://www.springer.com/us/book/9780387712642&#34;&gt;Lynch&lt;/a&gt; and &lt;a href=&#34;http://www.springer.com/us/book/9780387922997&#34;&gt;Hoff&lt;/a&gt;, neither of which really stuck with me. Actually, most Bayesian stats books I read didn’t stick with me :smile: . (&lt;a href=&#34;http://www.amazon.com/Bayesian-Statistics-Introduction-Peter-Lee/dp/1118332571&#34;&gt;Lee&lt;/a&gt; also has an introductory text, but I haven’t read it.)&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;Sticking with introductory level, John Kruschke has a popular &lt;a href=&#34;https://sites.google.com/site/doingbayesiandataanalysis/&#34;&gt;book&lt;/a&gt; with its quirky dog cover.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;http://www.indiana.edu/~kruschke/DoingBayesianDataAnalysis/DBDA2Ecover.png&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;I came a bit late to the Kruschke party, which meant that the two biggest advantages of the book (easy explanation of Bayesian stats and pre-written R functions) were not particularly useful to me, as I was already reasonably proficient in R and understood Bayesian stats quite well. Still, his book is very popular for a reason, which shows just how prevalent the problem of ‘writing-Bayesian-stats-books-for-people-who-are-already-awesome-at-statistics’ is. However, I like to open things up and poke around, and his closed system of pre-written functions didn’t work so well for me (plus, the functions are quite badly written, in my opinion). Closed ecosystems of functions like this are a thing of the past (see &lt;a href=&#34;https://cran.r-project.org/web/packages/LaplacesDemon/index.html&#34;&gt;Laplace’s Demon&lt;/a&gt;), the future is incorporating well-known methods and function calls with Bayesian machinery running under the hood (such as &lt;a href=&#34;https://cran.r-project.org/web/packages/rstanarm/vignettes/rstanarm.html&#34;&gt;rstanarm&lt;/a&gt;). Anyway, for someone starting off, it’s a recommended read. Kruschke has some interesting &lt;a href=&#34;http://www.indiana.edu/~kruschke/BEST/BEST.pdf&#34;&gt;papers&lt;/a&gt; too.&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;There are also some ‘classics’ of Bayesian statistics, perhaps the most well-known being the canonical &lt;a href=&#34;http://www.stat.columbia.edu/~gelman/book/&#34;&gt;Bayesian Data Analysis&lt;/a&gt; by Andrew Gelman &amp;amp; co. I don’t know what keeps me away from this book. It’s very highly regarded (pretty much as &lt;em&gt;the&lt;/em&gt; book on Bayesian stats) and well-written, and has a section on computation with &lt;a href=&#34;http://mc-stan.org/&#34;&gt;Stan&lt;/a&gt; etc., but I just never seem to sit down and read it. Who knows why.&lt;sup id=&#34;a5&#34;&gt;&lt;a href=&#34;#fn5&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
&lt;img src=&#34;http://i.imgur.com/hfaZkl3.png?1&#34;/&gt;
&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;Of course, there are tons of books on this subject. I could literally fill a long blog post on the books I started and just didn’t like for whatever reason. There are some that are encyclopaedic (&lt;a href=&#34;http://webspace.qmul.ac.uk/pcongdon/&#34;&gt;Congdon’s&lt;/a&gt; long list of Bayesian books, for example), others, designed for business students, that were just kind of ‘meh’: &lt;a href=&#34;http://www.springer.com/us/book/9780387389837&#34;&gt;Marin &amp;amp; Robert&lt;/a&gt; and &lt;a href=&#34;http://www.wiley.com/WileyCDA/WileyTitle/productCd-0470863676.html&#34;&gt;Rossi&lt;/a&gt;, for example. Others are useful for learning Bayesian methods &lt;em&gt;and&lt;/em&gt; &lt;code&gt;R&lt;/code&gt;, such as Jim Albert’s &lt;a href=&#34;https://books.google.com.br/books/about/Bayesian_Computation_with_R.html?id=kVk_WHFfIrMC&amp;amp;redir_esc=y&#34;&gt;book&lt;/a&gt;, &lt;em&gt;Bayesian Computation with R&lt;/em&gt;. This is a really useful book actually, but like I said earlier with reference to Kruschke, by the time I came to it, I was already using &lt;code&gt;JAGS&lt;/code&gt; and on a different path (&lt;a href=&#34;http://robertmyles.github.io//Stan-JAGS.html&#34;&gt;ideal points&lt;/a&gt; etc.) and so I had no great use for Albert’s &lt;code&gt;R&lt;/code&gt; functions. Still, it’s a well-regarded book by an acknowledged &lt;code&gt;R&lt;/code&gt; expert. There are also good books on Bayesian econometrics (&lt;a href=&#34;http://www.wiley.com/legacy/wileychi/koopbayesian/&#34;&gt;Koop&lt;/a&gt;) and time-series (&lt;a href=&#34;https://books.google.com.br/books/about/Applied_Bayesian_Forecasting_and_Time_Se.html?id=LAcp-ZwnyxIC&amp;amp;redir_esc=y&#34;&gt;Pole, West &amp;amp; Harrison&lt;/a&gt;, haaard) and Jeff Gill has &lt;a href=&#34;https://www.crcpress.com/Bayesian-Methods-A-Social-and-Behavioral-Sciences-Approach-Third-Edition/Gill/9781439862483&#34;&gt;one&lt;/a&gt; for the social &amp;amp; behavioural sciences (I &lt;em&gt;really&lt;/em&gt; didn’t get into this); there are also many others throughout the specific fields of the sciences.&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
&lt;img src=&#34;http://i.imgur.com/M7y9pgs.png?2&#34;/&gt;
&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;The emphasis on &lt;code&gt;R&lt;/code&gt; is something that has carried through to the newer batch of Bayesian statistics books, which place more emphasis on the ‘data analysis’ part (that is, being empirical instead of theoretical, and getting your hands dirty with computer programming in &lt;code&gt;R&lt;/code&gt; from the off) than on theoretical underpinnings. You will find some targeted at a Python audience, for example, Davidson-Pilon’s &lt;a href=&#34;http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/&#34;&gt;book&lt;/a&gt;, which is available as an editable github-type-webbook on the net, as well as a printed book. (Its title will tell you a bit about the Python audience it aims for – more computer programmers than the academic/statistician audience that use &lt;code&gt;R&lt;/code&gt;. Indeed, most of the Python Bayesian analysis resources are found on the web as opposed to in books. Although some are just books on the web in &lt;a href=&#34;http://www.greenteapress.com/thinkbayes/thinkbayes.pdf&#34;&gt;pdf format&lt;/a&gt;.) For me personally, this is good news. I liked the theoretical knowledge that I gained from Bernardo &amp;amp; Smith, but once I had to delve into understanding matrix algebra (just to see a linear regression derivation) or complex characteristics of probability distributions, I was already thinking of how I’d rather have a beer. Programming, at least for me, is a perfect way to connect the theory and the concepts to the reality of actually &lt;em&gt;doing&lt;/em&gt; some Bayesian analysis.&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;This brings me nicely to two books that I think really utilise this approach to good effect, one recent, one a decade or so old: Richard McElreath’s &lt;a href=&#34;http://xcelab.net/rm/statistical-rethinking/&#34;&gt;Statistical Rethinking&lt;/a&gt; (new) and Gelman &amp;amp; Hill’s &lt;a href=&#34;http://www.stat.columbia.edu/~gelman/arm/&#34;&gt;Data Analysis Using Regression and Multilevel/Hierarchical Models&lt;/a&gt; (older). While I’ve only recently started reading McElreath’s book, it seems like &lt;strong&gt;exactly&lt;/strong&gt; the type of book that I would have liked to have when I started out. No complicated mathematics, just sensible advice and a heavy emphasis on doing analysis in R. The book is well-written (and very well backed up with references, there’s a ton of information to follow-up from the endnotes if you’re so inclined) and contains lucid arguments for why the author believes we need to approach statistics from a fresh angle. Although I haven’t finished it, I do recommend it already.&lt;/p&gt;
&lt;p&gt;It’s similar in some ways to Gelman &amp;amp; Hill’s book, and one can see the influence of Andrew Gelman (particularly through his emphasis on the ‘doing’ of Bayesian statistics) in Statistical Rethinking. &lt;em&gt;Data Analysis Using…&lt;/em&gt; is likewise focused on analysis, learned through computer programming. It features both frequentist and Bayesian takes on statistical methods, and contains detailed computer code for (the now somewhat dated) &lt;code&gt;BUGS&lt;/code&gt; language (see &lt;a href=&#34;http://robertmyles.github.io//Stan-JAGS.html&#34;&gt;here&lt;/a&gt; (also linked to above) for why &lt;code&gt;BUGS&lt;/code&gt; and its cousin &lt;code&gt;JAGS&lt;/code&gt; are not always optimal for Bayesian analysis). It also contains some sage advice for researchers: try out simple models using quick methods like &lt;code&gt;lm()&lt;/code&gt; as you build up your model (advice that I certainly needed on at least one occasion).&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
&lt;img src=&#34;http://i.imgur.com/oH57M4t.png?1&#34;/&gt;
&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;So that’s my take on Bayesian statistics/data analysis books. As befits the age we live in, you’ll likely learn just as much from sites like &lt;a href=&#34;http://stackoverflow.com/search?q=Bayesian+&#34;&gt;Stack Overflow&lt;/a&gt; or from &lt;a href=&#34;https://darrenjw.wordpress.com/2012/11/20/getting-started-with-bayesian-variable-selection-using-jags-and-rjags/&#34;&gt;blog&lt;/a&gt; &lt;a href=&#34;https://twiecki.github.io/blog/2015/11/10/mcmc-sampling/&#34;&gt;posts&lt;/a&gt; and &lt;a href=&#34;https://rpubs.com/corey_sparks/30893&#34;&gt;RPubs&lt;/a&gt; and &lt;a href=&#34;https://github.com/RobertMyles/Bayesian-Ideal-Point-IRT-Models&#34;&gt;Github&lt;/a&gt; than you will from books. Academic papers often helped me more than books too. Still, a good book can teach you a hell of a lot in a consistent way. There are many referenced in this post, some better than others, but all have their qualities. For me specifically, someone who is not mad about reading lots of mathematics, the last two are my recommendations. For others, this will obviously be different (I know someone who loves Jackman’s book, for example).&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;em&gt;By the way, there are some informal books on the subject, such as Nate Silver’s &lt;a href=&#34;http://www.penguinrandomhouse.com/books/305826/the-signal-and-the-noise-by-nate-silver/9780143125082/&#34;&gt;The Signal and the Noise&lt;/a&gt;, or McGrayne’s &lt;a href=&#34;https://www.amazon.ca/Theory-That-Would-Not-Die/dp/0300169698/181-0429523-7916830?ie=UTF8&amp;amp;tag=vglnk-ca-c250-20&#34;&gt;The Theory That Would Not Die&lt;/a&gt;. I’ve given Amazon or publisher links for all these books, bar a few, but they can be found in other places too…you know what I’m talking about. Buy the ones you like, though!&lt;/em&gt; :cop:&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;b id=&#34;fn1&#34;&gt;1&lt;/b&gt; Maybe this formula wouldn’t have made much sense to the ol’ Reverend Thomas Bayes either, since he used the Newtonian style of geometric exposition. For the history of the theorem, see &lt;a href=&#34;https://www.amazon.ca/Theory-That-Would-Not-Die/dp/0300169698/181-0429523-7916830?ie=UTF8&amp;amp;tag=vglnk-ca-c250-20&#34;&gt;McGrayne&lt;/a&gt;. For a history of statistics in general, including Bayes (and Laplace, who probably did much more to develop Bayesian statistics than Bayes ever did) see the fantastic &lt;a href=&#34;http://www.hup.harvard.edu/catalog.php?isbn=9780674403413&#34;&gt;Stigler&lt;/a&gt;. &lt;a href=&#34;#a1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;b id=&#34;fn2&#34;&gt;2&lt;/b&gt; That would be ‘frequentist’ or ‘classical’ (or ‘traditional’) statistics (take your pick of adjective). Most of the Bayesian books above will have sections comparing the traditions. McElreath doesn’t bother, which is a nice development in its own way. &lt;a href=&#34;#a2&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;b id=&#34;fn3&#34;&gt;3&lt;/b&gt; Although there is only ever one core method: &lt;span class=&#34;math display&#34;&gt;\[posterior \propto prior \times likehood \]&lt;/span&gt;. &lt;a href=&#34;#a3&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;b id=&#34;fn4&#34;&gt;4&lt;/b&gt; I’ve learned much more from Jackman’s various political science articles, in which he uses Bayesian methods, than this book, to be honest. &lt;a href=&#34;#a4&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;b id=&#34;fn5&#34;&gt;5&lt;/b&gt; Speaking of Gelman, he has a literal treasure trove of papers and web discussions on the subject of Bayesian data analysis. See his &lt;a href=&#34;http://andrewgelman.com/&#34;&gt;site&lt;/a&gt; for many links to those. &lt;a href=&#34;#a5&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;link rel=&#34;image_src&#34; href=&#34;http://i.imgur.com/aB6eoBS.png?1&#34; /&gt;&lt;/p&gt;


&lt;!-- BLOGDOWN-HEAD




/BLOGDOWN-HEAD --&gt;
</description>
    </item>
    
    <item>
      <title>Web Navigation in R with RSelenium</title>
      <link>/web-navigation-and-scraping-with-r.html</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>/web-navigation-and-scraping-with-r.html</guid>
      <description>&lt;!-- BLOGDOWN-BODY-BEFORE

/BLOGDOWN-BODY-BEFORE --&gt;

&lt;p&gt; &lt;/p&gt;
&lt;p&gt;It goes almost without saying that the internet itself is the richest database available to us. From a 2014 &lt;a href=&#34;http://aci.info/2014/07/12/the-data-explosion-in-2014-minute-by-minute-infographic/&#34;&gt;blog post&lt;/a&gt;, it was claimed that &lt;em&gt;every minute&lt;/em&gt; :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Facebook users share nearly 2.5 million pieces of content.&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Twitter users tweet nearly 300,000 times.&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Instagram users post nearly 220,000 new photos.&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;YouTube users upload 72 hours of new video content.&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Apple users download nearly 50,000 apps.&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Email users send over 200 million messages.&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;Amazon generates over $80,000 in online sales.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Regardless of the accuracy of these claims, it is obvious to everyone that there is tons of information on the web. For researchers, then, the question is: how can you access all this information? You can of course go to specific, dedicated databases and download what you’re looking for, for example from the World Bank &lt;a href=&#34;http://databank.worldbank.org/data/home.aspx&#34;&gt;databank&lt;/a&gt;. However, there are drawbacks to this approach. It can become tiresome when you need to collect lots of data on different items (the World Bank databank is well organised, but not all databases are like that…to put it politely). Some only let you download small, specific sections of a bigger database, meaning you have to return time and time again to the starting page to enter new information in order to retrieve the data you want. (Another thing is that we’re not quite utilising the web &lt;em&gt;itself&lt;/em&gt; as the database either.)&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;To deal with the first problem, you can automate the search process by driving a web browser with R.&lt;sup id=&#34;a1&#34;&gt;&lt;a href=&#34;#fn1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; This is different from ‘web-scraping’. Web-scraping takes the webpage as a html document and allows you to read information from it. It’s quite a straightforward process, with plenty of R packages around to help you do it. &lt;a href=&#34;https://github.com/hadley/rvest&#34;&gt;rvest&lt;/a&gt; in particular is quite easy, although I’ve found the &lt;a href=&#34;https://cran.r-project.org/web/packages/XML/XML.pdf&#34;&gt;XML&lt;/a&gt; package to be more powerful. (Web-scraping deals with the second issue above, in that it does treat the web itself as a database.)&lt;/p&gt;
&lt;p&gt;To drive a web browser in R, there are two packages (that I’m aware of) that can be used. One is &lt;a href=&#34;https://github.com/ropensci/RSelenium&#34;&gt;RSelenium&lt;/a&gt; by John Harrison, and &lt;a href=&#34;https://github.com/crubba/Rwebdriver&#34;&gt;Rwebdriver&lt;/a&gt; by Christian Rubba. I prefer &lt;code&gt;RSelenium&lt;/code&gt; and so I’ll use this package in the examples below.&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;If you don’t have it already installed, you’ll need to download this package and load it into R.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;install.packages(&amp;quot;RSelenium&amp;quot;)
library(&amp;quot;RSelenium&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You will also need to download the Selenium standalone server. You can get it from &lt;a href=&#34;http://www.seleniumhq.org/download/&#34;&gt;here&lt;/a&gt;. Opening this file automatically from &lt;code&gt;RSelenium&lt;/code&gt; can be problematic&lt;sup id=&#34;a2&#34;&gt;&lt;a href=&#34;#fn2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;, and so I’ve found the most straightforward way is to manually click on it and open it that way before you start.&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;To get started with &lt;code&gt;RSelenium&lt;/code&gt;, you’ll need to give your browser somewhere to go. For this example, I’m going to go to the funding management section of Brazilian National Health Service, the &lt;em&gt;Fundo Nacional de Saúde&lt;/em&gt;. From here, I’m going to get data for every municipality in every state over a period of some years. To do this manually would be a serious headache and would most likely lead to me making errors by forgetting where I am, which state is next, what municipality I just downloaded, and so on. Actually, you can be guaranteed I’d make those mistakes.&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;URL &amp;lt;- &amp;quot;http://www.fns.saude.gov.br/indexExterno.jsf&amp;quot;
#checkForServer(dir=&amp;quot;[DIRECTORY WHERE THE SELENIUM SERVER IS]&amp;quot;, update=FALSE)
#checkForServer(dir=&amp;quot;[DIRECTORY WHERE THE SELENIUM SERVER IS]&amp;quot;, update=TRUE) # if you want to update
#startServer(dir=&amp;quot;[DIRECTORY WHERE THE SELENIUM SERVER IS]&amp;quot;) #none of these three are necessary if you click on the server first and manually open it.  

fprof &amp;lt;- makeFirefoxProfile(list(browser.download.dir = &amp;quot;[DOWNLOAD DIRECTORY]&amp;quot;,  
browser.download.folderList = 2L,   
browser.download.manager.showWhenStarting=FALSE,  
browser.helperApps.neverAsk.saveToDisk = &amp;quot;application/octet-stream&amp;quot;))   

remDr &amp;lt;- remoteDriver(extraCapabilities=fprof)
remDr$open()  &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;So now your browser should be open. Here I’ve used a profile for Firefox because I will download files and I don’t want to deal with the download window that pops up in Firefox (you need to enter your download folder where it says ‘&lt;code&gt;[DOWNLOAD DIRECTORY]&lt;/code&gt;’, by the way. And you can also run &lt;code&gt;RSelenium&lt;/code&gt; on Chrome and &lt;a href=&#34;http://rpubs.com/johndharrison/13885&#34;&gt;other browsers&lt;/a&gt;, and even use a &lt;a href=&#34;https://rpubs.com/johndharrison/RSelenium-headless&#34;&gt;headless browser&lt;/a&gt; which speeds things up.) If you didn’t need to deal with download boxes and pop-ups and the like, you only need &lt;code&gt;remDr &amp;lt;- remoteDriver$new()&lt;/code&gt;, which will automatically open up a Firefox browser window. These particular files were recognised by Firefox as being binary files, and so I have disabled the download box for files of the type “application/octet-stream”. Other file types need a different setting.&lt;/p&gt;
&lt;p&gt;This website has a drop-down box on the left hand side that we’re going to use. What we will input into this is, in turn, a list of years, states, and municipalities. After that we will click on “Consultar” (for those of you who don’t speak Portuguese, I’m quite sure you can figure out what that means). Clicking this will bring us to a new page, from which we can download the data we’re looking for in a .csv file.&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;So let’s create our inputs:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;InputYear &amp;lt;- list(&amp;quot;2016&amp;quot;, &amp;quot;2015&amp;quot;, &amp;quot;2014&amp;quot;, &amp;quot;2013&amp;quot;, &amp;quot;2012&amp;quot;, &amp;quot;2011&amp;quot;, &amp;quot;2010&amp;quot;, &amp;quot;2009&amp;quot;)  

Input &amp;lt;- list(&amp;quot;ACRE&amp;quot;, &amp;quot;ALAGOAS&amp;quot;, &amp;quot;AMAPA&amp;quot;, &amp;quot;AMAZONAS&amp;quot;, &amp;quot;BAHIA&amp;quot;, &amp;quot;CEARA&amp;quot;, &amp;quot;DISTRITO FEDERAL&amp;quot;, &amp;quot;ESPIRITO SANTO&amp;quot;, &amp;quot;GOIAS&amp;quot;, &amp;quot;MARANHAO&amp;quot;, &amp;quot;MATO GROSSO&amp;quot;, &amp;quot;MATO GROSSO DO SUL&amp;quot;, &amp;quot;MINAS GERAIS&amp;quot;, &amp;quot;PARA&amp;quot;, &amp;quot;PARAIBA&amp;quot;, &amp;quot;PARANA&amp;quot;, &amp;quot;PERNAMBUCO&amp;quot;, &amp;quot;PIAUI&amp;quot;, &amp;quot;RIO DO JANEIRO&amp;quot;, &amp;quot;RIO GRANDE DO NORTE&amp;quot;, &amp;quot;RIO GRANDE DO SUL&amp;quot;, &amp;quot;RONDONIA&amp;quot;, &amp;quot;RORAIMA&amp;quot;, &amp;quot;SANTA CATARINA&amp;quot;, &amp;quot;SAO PAULO&amp;quot;, &amp;quot;SERGIPE&amp;quot;, &amp;quot;TOCANTINS&amp;quot;)  

Input_Mun &amp;lt;- &amp;quot;TODOS DA UF&amp;quot; #this will select all municipalities  &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;In order to get all this done, I will use a for loop in R which will first loop over the years, and then states, thereby selecting all states in a given year. In the following code, you will see &lt;code&gt;RSelenium&lt;/code&gt; commands that are quite different to regular commands in R. First of all, &lt;code&gt;RSelenium&lt;/code&gt; operates by way of two environments: one is remoteDriver environment, the other a webElement environment. These have specific options available to them (see the help section on each for a list and explanations). Some of the most useful are &lt;code&gt;findElement()&lt;/code&gt; (an option of remoteDriver), &lt;code&gt;sendKeystoElement()&lt;/code&gt; and &lt;code&gt;clickElement()&lt;/code&gt; (both options of webElement, as &lt;code&gt;remDr$findElement&lt;/code&gt; returns an object of webElement class). We will use these to navigate around the page and click on specific elements.&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;Speaking of elements on a page, this is actually the most crucial part of the process to get right (and can be the most frustrating). Some have recommended &lt;a href=&#34;http://selectorgadget.com/&#34;&gt;selectorgadget&lt;/a&gt;, but finding elements can be done in Firefox or Chrome without selectorgadget – you just right-click the element in question and select “Inspect” or “Inspect Element”. This will bring up a chaotic-looking panel, full of html, css and javascript code. Luckily, there are easy options in Firefox and Chrome for finding what we need. After you right-click the element that you want (the one you would have clicked if you were navigating the page manually), click “Inspect” and then this element of the html code will be highlighted. Right-click on this again and you will see the option to copy. In Chrome, you will have the option to copy the xpath or css selector (“selector”); in Firefox you can copy the css selector (“unique selector”). I have used other options below to give more examples, such as ‘id’. This can be copied directly from the html code, and ‘class’ and ‘name’ can be used in a similar fashion. In general, css selectors are the easiest to work with.&lt;/p&gt;
&lt;p&gt;A quick note on some other aspects of the code. &lt;code&gt;Sys.sleep&lt;/code&gt; is used in order to be nice– you don’t want to bombard the website with all of your requests in rapid-fire fashion; after all, they may block you. So this spaces out our commands. This is also useful for when you may have to wait for an element to load on the page before you can click on it. I have used &lt;code&gt;paste()&lt;/code&gt; in order to include the loop counters in the css selector– just a little trick to make things easier. Some elements have &lt;code&gt;\\&lt;/code&gt; in the code: this is because the original had a single backslash, which is an escape character in R, and so the string is unreadable. Hence the added backslash. You will also see the use of &lt;code&gt;try()&lt;/code&gt; – in this case, there is a state that does not load like the others (the Federal District) and so this automated process will not work here. &lt;code&gt;try()&lt;/code&gt; allows R to try anyway, and if it fails, the loop just continues to the next iteration.&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;for(i in 1:length(InputYear)){
  for(j in 1:length(Input)){
    remDr$navigate(URL)
    #Year:
    webElem &amp;lt;- remDr$findElement(using = &amp;quot;id&amp;quot;, value = &amp;quot;formIndex:j_idt48&amp;quot;)
    webElem$clickElement() #click on the drop-down year box
    Sys.sleep(2)
    webElem &amp;lt;- remDr$findElement(using = &amp;quot;id&amp;quot;, value=&amp;quot;formIndex:j_idt48_input&amp;quot;)
    Sys.sleep(2)
    webElem$sendKeysToElement(InputYear[i]) #send the year to the box
    webElem &amp;lt;- remDr$findElement(using = &amp;quot;css&amp;quot;, value=&amp;quot;li.ui-state-active&amp;quot;)
    webElem$clickElement() #click on the active element (the year we sent)
    Sys.sleep(2)
    #State:
    webElem &amp;lt;- remDr$findElement(using = &amp;quot;id&amp;quot;, value = &amp;quot;formIndex:sgUf&amp;quot;)
    webElem$clickElement()
    Sys.sleep(2)
    webElem$sendKeysToElement(Input[j]) #enter the state into the drop-down box
    CSS &amp;lt;- paste(&amp;quot;#formIndex\\3a sgUf_panel &amp;gt; div &amp;gt; ul &amp;gt; li:nth-child(&amp;quot;, j+2, &amp;quot;)&amp;quot;, sep=&amp;quot;&amp;quot;)
    webElem &amp;lt;- remDr$findElement(using = &amp;quot;css&amp;quot;, value = CSS)
    Sys.sleep(1)
    webElem$clickElement()
    Sys.sleep(3)
    #Municipality:
    webElem &amp;lt;- remDr$findElement(using = &amp;#39;id&amp;#39;, value = &amp;#39;formIndex:cbMunicipio&amp;#39;)
    webElem$clickElement()
    Sys.sleep(2)
    webElem &amp;lt;- remDr$findElement(using = &amp;#39;css&amp;#39;, value=&amp;#39;#formIndex\\3a cbMunicipio_panel &amp;gt; div &amp;gt; ul &amp;gt; li:nth-child(2)&amp;#39;)
    webElem$sendKeysToElement(list(Input_Mun))
    webElem$clickElement()
    Sys.sleep(4)
    #&amp;quot;Consultar&amp;quot;:
    webElem &amp;lt;- remDr$findElement(using = &amp;#39;xpath&amp;#39;, value = &amp;#39;//*[@id=&amp;quot;formIndex:j_idt60&amp;quot;]&amp;#39;)
    Sys.sleep(2)
    webElem$clickElement() 
    Sys.sleep(6)
    #Download the .csv:
    webElem &amp;lt;- try(remDr$findElement(using = &amp;#39;xpath&amp;#39;, value = &amp;#39;//*[@id=&amp;quot;formIndex&amp;quot;]/div[4]/input&amp;#39;), silent=T)
    try(webElem$clickElement(), silent=T)
    Sys.sleep(3)
}}  &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;So after all this, we’ll have a bunch of .csv files in out download folder, that you can import into R and mess around with. To load them all in together, you could use the following code:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;readr&amp;quot;)
setwd(&amp;quot;[THE DOWNLOAD FOLDER YOU USED]&amp;quot;)
fileNames &amp;lt;- list.files(path = getwd(), pattern = &amp;quot;*.csv&amp;quot;)
data &amp;lt;- rbindlist(lapply(fileNames, read_csv2,  
col_names=c(&amp;quot;Ano&amp;quot;, &amp;quot;UF_MUNICIPIO&amp;quot;, &amp;quot;IBGE&amp;quot;, &amp;quot;ENTIDADE&amp;quot;, &amp;quot;CPF_CNPJ&amp;quot;,  
&amp;quot;Bloco&amp;quot;, &amp;quot;Componente&amp;quot;, &amp;quot;Acao_Servico_Estrategia&amp;quot;, &amp;quot;Competencia_Parcela&amp;quot;,  
&amp;quot;No_OB&amp;quot;, &amp;quot;Data_OB&amp;quot;, &amp;quot;Banco_OB&amp;quot;, &amp;quot;Agencia_OB&amp;quot;, &amp;quot;Conta_OB&amp;quot;, &amp;quot;Valor_Total&amp;quot;,  
&amp;quot;Desconto&amp;quot;, &amp;quot;Valor_Liquido&amp;quot;, &amp;quot;Observacao&amp;quot;, &amp;quot;Processo&amp;quot;, &amp;quot;Tipo Repasse&amp;quot;,  
&amp;quot;No_Proposta&amp;quot;), skip = 1, locale=locale(decimal_mark=&amp;quot;,&amp;quot;, grouping_mark=&amp;quot;.&amp;quot;)))  &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;And there you go, all the data you wanted scraped automatically from the web. In this example, we were downloading a file, but you could be navigating around in order to arrive at a certain page and then to scrape the contents of that page. You can do that in a number of ways, by combining &lt;code&gt;RSelenium&lt;/code&gt; and other packages, such as &lt;code&gt;XML&lt;/code&gt; and &lt;code&gt;rvest&lt;/code&gt;. For a solution using only &lt;code&gt;RSelenium&lt;/code&gt;, we can first create an empty dataframe and then fill it with the &lt;code&gt;getElementText()&lt;/code&gt; option of the webElement class. So, for example, I was getting vote proposal content from the Brazilian Senate. I used &lt;code&gt;RSelenium&lt;/code&gt; to navigate to the pages that I wanted, as is shown above, and then I stored the Content and the Index of the vote (which were stored on the page as html text elements) as entries in the Index dataframe, using &lt;code&gt;webElem$getElementText()&lt;/code&gt;. Afterwards, I used various combinations of &lt;code&gt;stringr&lt;/code&gt; package functions and &lt;code&gt;gsub&lt;/code&gt; to clean up the text.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Index &amp;lt;- data.frame(Content=NA, Index=NA)  
Index[i,1] &amp;lt;- webElem$getElementText()  
   ...    
Index[i,2] &amp;lt;- webElem$getElementText()  &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;You can also get the html and parse it using &lt;code&gt;XML&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;elemtxt &amp;lt;- webElem$getElementAttribute(&amp;quot;outerHTML&amp;quot;)  
elemxml &amp;lt;- htmlTreeParse(elemtxt, asText=TRUE, encoding=&amp;quot;UTF-8&amp;quot;, useInternalNodes=TRUE)  
Text &amp;lt;- html_text(elemxml, trim=TRUE)  &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;And then you have the text from the webpage stored as data in R. Magic! :metal:&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;b id=&#34;fn1&#34;&gt;1&lt;/b&gt; It is often argued that R is not the best for this application, with Python often offered as a better alternative. In my experience, I’ve found R to be pretty good for this sort of thing, with delays being caused more by the browser/net speed than R. The scripts can be ugly, but using Selenium in Python looks pretty similar anyway. &lt;a href=&#34;http://stackoverflow.com/questions/17540971/how-to-use-selenium-with-python&#34;&gt;This question&lt;/a&gt; on Stack Overflow gives some instructions. &lt;a href=&#34;#a1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;b id=&#34;fn2&#34;&gt;2&lt;/b&gt; See &lt;a href=&#34;https://github.com/ropensci/RSelenium/issues/54&#34;&gt;this&lt;/a&gt; discussion. &lt;a href=&#34;#a2&#34;&gt;↩&lt;/a&gt; &lt;link rel=&#34;image_src&#34; href=&#34;http://i.imgur.com/v7y6SVt.png?1&#34; /&gt;&lt;/p&gt;


&lt;!-- BLOGDOWN-HEAD




/BLOGDOWN-HEAD --&gt;
</description>
    </item>
    
    <item>
      <title>Write your thesis or paper in R Markdown!</title>
      <link>/r-markdown.html</link>
      <pubDate>Fri, 15 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>/r-markdown.html</guid>
      <description>&lt;!-- BLOGDOWN-BODY-BEFORE

/BLOGDOWN-BODY-BEFORE --&gt;

&lt;p&gt; &lt;/p&gt;
&lt;p&gt;There are many reasons why you would want to use some variant of Markdown for writing, and indeed, posts are common on the net as to why you should.&lt;sup id=&#34;a1&#34;&gt;&lt;a href=&#34;#fn1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; A simple summary of the reasons are that Markdown is: 1) easy; 2) easy; 3) yup, you guessed it – it’s easy.&lt;/p&gt;
&lt;p&gt;One variant of Markdown is R Markdown, developed by the &lt;a href=&#34;https://www.rstudio.com/&#34;&gt;RStudio&lt;/a&gt; team, and in particular the genius that is &lt;a href=&#34;http://yihui.name/knitr/&#34;&gt;Yihui Xie&lt;/a&gt;, creator of the &lt;code&gt;knitr&lt;/code&gt; R package. R Markdown is pretty much like regular Markdown, except you get a whole load of nice extra features, including the ability to run code chunks, produce .pdfs and presentations, and even .docx (if you really, really want to&lt;sup id=&#34;a2&#34;&gt;&lt;a href=&#34;#fn2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;). Indeed, the ioslides presentation format lets you use the power of html and css to make browser-based presentations.&lt;/p&gt;
&lt;p&gt;But surely academic papers require certain formats, and sometimes mathematical expressions and funny Greek letters? Well, sure. Academic papers, particularly theses, often have set formats that you must adhere to. And since Markdown is quite a simple language, it doesn’t have the advanced power of &lt;span class=&#34;math inline&#34;&gt;\(\LaTeX\)&lt;/span&gt; to position things in specific ways.&lt;/p&gt;
&lt;div id=&#34;latex-in-r-markdown&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;math inline&#34;&gt;\(\LaTeX\)&lt;/span&gt; in R Markdown&lt;/h3&gt;
&lt;p&gt;Enter R Markdown! Although you might (depends on the Markdown) have to do something like &lt;code&gt;{% raw %}\\(\LaTeX\\){% endraw %}&lt;/code&gt; to get the word &lt;span class=&#34;math inline&#34;&gt;\(\LaTeX\)&lt;/span&gt; in your Markdown, with R Markdown it’s just &lt;code&gt;$ \LaTeX $&lt;/code&gt;. I used Mathjax characters in my thesis, and all worked fine using this method (&lt;a href=&#34;http://www.onemathematicalcat.org/MathJaxDocumentation/TeXSyntax.htm&#34;&gt;here’s&lt;/a&gt; a nice link showing all the possible characters you can create with Mathjax). Nice ‘n’ easy, lemon squeezy. Inline &lt;span class=&#34;math inline&#34;&gt;\(\LaTeX\)&lt;/span&gt; expressions get one &lt;code&gt;$&lt;/code&gt;, centred equations get two: &lt;code&gt;$$&lt;/code&gt;, and both need the equivalent to finish the expression. For example, in my first &lt;a href=&#34;http://robertmyles.github.io//post1.html&#34;&gt;post&lt;/a&gt;, I had the equation:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_{ij} = \beta_j\boldsymbol{x_i} - \alpha_j.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In R Markdown, this is:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$$ y_{ij} = \beta_j\boldsymbol{x_i} - \alpha_j.$$&lt;/code&gt; Simple!&lt;/p&gt;
&lt;p&gt;So that’s math and funny characters done. What else can we do in R Markdown?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;images&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Images&lt;/h3&gt;
&lt;p&gt;Well, all the image-placement power of &lt;span class=&#34;math inline&#34;&gt;\(\LaTeX\)&lt;/span&gt; is also available. So &lt;code&gt;\begin{figure}&lt;/code&gt; (or subfigure and wrapfigure), &lt;code&gt;\centering&lt;/code&gt;, &lt;code&gt;\includegraphics&lt;/code&gt; and &lt;code&gt;\caption&lt;/code&gt; all work as they should. I found minipage to be particularly helpful. You can use &lt;code&gt;\&lt;/code&gt; with two spaces after it to organise blank space, or &lt;code&gt;\newpage&lt;/code&gt; to force a new page.&lt;/p&gt;
&lt;p&gt;Of course, that supposing that you want to use &lt;span class=&#34;math inline&#34;&gt;\(\LaTeX\)&lt;/span&gt; for images. R Markdown’s own syntax for images is quite simple: &lt;code&gt;![Caption](file.png)&lt;/code&gt;, where ‘Caption’ is your image caption and ‘file.png’ your image file (you can use other formats, such as .pdf too). However, positioning may become a problem using this image-placing syntax. It’s worth taking the extra time to learn the &lt;span class=&#34;math inline&#34;&gt;\(\LaTeX\)&lt;/span&gt; if you don’t know it.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;tables&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Tables&lt;/h3&gt;
&lt;p&gt;Tables are a &lt;em&gt;little&lt;/em&gt; annoying sometimes in any Markdown. It depends. If the simple one works for you, then great – they’re quick and easy. If you have to use grid tables, things take longer (for some reason, only grid tables worked for me sometimes). There’s a &lt;a href=&#34;http://pandoc.org/README.html#tables&#34;&gt;simple guide&lt;/a&gt; on the pandoc site, since it is pandoc that is actually converting to and fro in all these different formats (pandoc is amazing). But a basic one is &lt;em&gt;really&lt;/em&gt; simple (from the pandoc site):&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;http://i.imgur.com/TcbAp2U.png&#34; alt=&#34;Table&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Table&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The table numbers will automatically increment, and the caption is set after the &lt;code&gt;:&lt;/code&gt; part. Indeed, &lt;code&gt;table&lt;/code&gt; is not even needed, using &lt;code&gt;:&lt;/code&gt; with give you a caption with &lt;code&gt;Table 1:&lt;/code&gt;, for your first table in the document.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;code&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Code&lt;/h3&gt;
&lt;p&gt;There may be a need for you to display code segments, particularly in a quantitative paper or thesis. Again, it’s very simple. In R Markdown, you do the following (I’m using &lt;code&gt;eval = FALSE&lt;/code&gt; here because I don’t want the code chunk to be evaluated):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;readr&amp;quot;)
data &amp;lt;- read_csv(&amp;quot;example.csv&amp;quot;)
data &amp;lt;- data[1:6, ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Which should produce:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;quot;readr&amp;quot;)
data &amp;lt;- read_csv(&amp;quot;example.csv&amp;quot;)
data &amp;lt;- data[1:6, ]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This useful for plotting simple graphs and things like that. The example I’ve shown &lt;em&gt;wouldn’t&lt;/em&gt; be a particularly good idea, since R will load in &lt;code&gt;example.csv&lt;/code&gt; every time you produce the pdf using the ‘knit’ button in RStudio. The &lt;code&gt;{r}&lt;/code&gt; prt also has optional arguments, such as &lt;code&gt;eval&lt;/code&gt;, which can be set to &lt;code&gt;TRUE&lt;/code&gt; or &lt;code&gt;FALSE&lt;/code&gt;, and tells R Markdown whether to evaluate the expression or not (useful for examples where you want to show the code but not run it).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;chapters-and-headings&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Chapters and Headings&lt;/h3&gt;
&lt;p&gt;Chapters and Headings are laughably simple in any Markdown, and R Markdown is no exception. &lt;code&gt;# Header 1&lt;/code&gt; will create the largest-sized header, &lt;code&gt;## Header 2&lt;/code&gt; a smaller one, and so on. To have these numbered, we’ll have to use another excellent feature of Markdown, the YAML block that goes on the top of the document.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-yaml-block&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The YAML block&lt;/h3&gt;
&lt;p&gt;The YAML block is what makes your R Markdown document possibly really fancy. It’s here that the &lt;span class=&#34;math inline&#34;&gt;\(\LaTeX\)&lt;/span&gt; packages are loaded, and here that you can specify various options that will have an impact on your document. So what the hell &lt;em&gt;is&lt;/em&gt; a YAML block, anyway? Well, maybe the easiest way to explain that is to show you mine&lt;sup id=&#34;a3&#34;&gt;&lt;a href=&#34;#fn3&#34;&gt;3&lt;/a&gt;&lt;/sup&gt; from my PhD &lt;a href=&#34;%7B%7B%20site.url%20%7D%7D/assets/Explaining%20the%20Determinants%20of%20Foreign%20Policy%20Voting%20Behaviour%20in%20the%20Brazilian%20Houses%20of%20Legislature.pdf&#34;&gt;thesis&lt;/a&gt;. It starts and ends with &lt;code&gt;---&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;---
title: &amp;quot;Explaining the Determinants of Foreign Policy Voting Behaviour in the Brazilian Houses of Legislature, with a Focus on the Senate&amp;quot;
author: &amp;quot;Robert Myles McDonnell&amp;quot;
date: &amp;quot;&amp;quot;
fontsize: 12pt
header-includes:
   - \usepackage{booktabs}
   - \usepackage{dcolumn}
   - \usepackage{wrapfig}
   - \usepackage{subcaption}
   - \usepackage{caption}
   - \usepackage[font=small,labelfont=bf]{caption}
   - \hypersetup{colorlinks=false}
documentclass: &amp;quot;article&amp;quot;
output:
  pdf_document:
    fig_caption: yes
    fig_height: 6
    fig_width: 7
    latex_engine: pdflatex
    number_sections: yes
    toc: yes
    toc_depth: 4
    citation_package: &amp;quot;natbib&amp;quot;
linestretch: 2
mainfont: &amp;quot;Linux Libertine O&amp;quot;
bibliography: ThesisLibrary.bib
csl: american-political-science-association.csl
biblio-style: apalike
---&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So, that’s quite extended, but maybe you won’t need all these things. One important thing to remember with the YAML block is that indentation &lt;em&gt;matters&lt;/em&gt;. When you have something like &lt;code&gt;output:&lt;/code&gt;, then the line &lt;code&gt;pdf document:&lt;/code&gt; is &lt;strong&gt;two&lt;/strong&gt; spaces indented. &lt;code&gt;fig_caption: yes&lt;/code&gt; is &lt;strong&gt;two more&lt;/strong&gt; spaces indented (four in total) and so are the other options to pdf_document. If you get your spacing wrong, it won’t work.&lt;/p&gt;
&lt;p&gt;Many of the options are self-explanatory: &lt;code&gt;linestretch&lt;/code&gt; is line-spacing, for example. One important option is &lt;code&gt;toc&lt;/code&gt; and its option &lt;code&gt;toc_depth&lt;/code&gt;. This is the &lt;strong&gt;t&lt;/strong&gt;able &lt;strong&gt;o&lt;/strong&gt;f &lt;strong&gt;c&lt;/strong&gt;ontents. &lt;code&gt;toc_depth&lt;/code&gt; is telling R Markdown how many levels you’d like: Chapter 4.1, Chapter 4.1.1 etc. More advanced elements can be changed too. For example, this thesis had a &lt;code&gt;documentclass&lt;/code&gt; of article, but you can write your own document class and therefore produce radically different documents. One example is an R Markdown &lt;a href=&#34;https://github.com/danielkrizian/resume_template&#34;&gt;version&lt;/a&gt; of Friggeri’s popular CV template. Other examples are rapidly proliferating on the web. The RStudio team have a new R package &lt;a href=&#34;https://github.com/rstudio/rticles&#34;&gt;rticles&lt;/a&gt; that has document templates for various academic journal styles. Load ’em up, and you’ve already got an easy R Markdown template for the journal in question. And for papers, enable the &lt;code&gt;abstract:&lt;/code&gt; option in the YAML header, write your abstract there, and voilà! You’ve got yourself a nice abstract.&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;So if writing your thesis (or a paper) in Microsoft Word or something similar sounds like an ordeal, and you’re really not such an expert on&lt;span class=&#34;math inline&#34;&gt;\(\LaTeX\)&lt;/span&gt;, maybe you should consider doing it in R Markdown. It has all the easiness of Markdown, with a couple of nice extras that help you make a quality document. See my thesis if you don’t believe me! :wink:&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;Update:&lt;br /&gt;
A colleague asked me how I produced the first few pages of my thesis, and I realised that I forgot to mention that you can include other documents, for example tex files, that may need to be part of your thesis. Many theses have strict guidelines for the introductory pages, which can be included in your R Markdown file as part of the YAML header section. The option is &lt;code&gt;includes&lt;/code&gt;, and it has the sub-options &lt;code&gt;in_header&lt;/code&gt;, &lt;code&gt;before_body&lt;/code&gt; and &lt;code&gt;after body&lt;/code&gt;. Like before, the spacing is meaningful in the YAML header, so these sub-options will need to be indented two spaces. For introductory pages of a thesis, your tex file will go in &lt;code&gt;before_body&lt;/code&gt;. (I have to admit that this option never worked well for me, I simply merged the .pdf produced from the tex file and the .pdf produced from the R Markdown document with Preview in OS X, but for others, it seems to work fine.) See &lt;a href=&#34;http://rmarkdown.rstudio.com/markdown_document_format.html&#34;&gt;here&lt;/a&gt; for examples. See &lt;a href=&#34;https://github.com/danilofreire/kcl-thesis-template-markdown&#34;&gt;here&lt;/a&gt; for a Markdown template for King’s College London’s PhD guidelines, by &lt;a href=&#34;http://danilofreire.com/&#34;&gt;Danilo Freire&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;b id=&#34;fn1&#34;&gt;1&lt;/b&gt; For example, &lt;a href=&#34;http://markdown-guide.readthedocs.org/en/latest/basics.html&#34;&gt;this cheatsheet&lt;/a&gt; &lt;a href=&#34;#a1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;b id=&#34;fn2&#34;&gt;2&lt;/b&gt; In my experience, I think you’re just going to end up editing these in Word anyway so I don’t know that it’s worth the bother to do in RStudio. You can if you want, I suppose.&lt;a href=&#34;#a2&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;b id=&#34;fn3&#34;&gt;3&lt;/b&gt; I’m including extra things here that I used over the process of making the thesis pdf, but it wasn’t what I used exactly in the end. I had some problems, that I can’t recall right now, with rendering bibliographical items so I switched to the default LaTeX renderer, pdflatex. Using this means you can’t use other fonts, like the Linux Libertine font above.&lt;a href=&#34;#a3&#34;&gt;↩&lt;/a&gt; &lt;link rel=&#34;image_src&#34; href=&#34;http://i.imgur.com/vywFhKA.png?1&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;


&lt;!-- BLOGDOWN-HEAD




/BLOGDOWN-HEAD --&gt;
</description>
    </item>
    
  </channel>
</rss>
